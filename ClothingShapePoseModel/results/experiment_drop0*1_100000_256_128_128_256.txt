>>> Initializing clothing shape model...
>>> Star initialized.
>>> Get parameters list...
>>> Length of pose: 150
>>> Length of shape: 20
>>> Length of data: 3000
>>> 100/3000 loading...>>> 200/3000 loading...>>> 300/3000 loading...>>> 400/3000 loading...>>> 500/3000 loading...>>> 600/3000 loading...>>> 700/3000 loading...>>> 800/3000 loading...>>> 900/3000 loading...>>> 1000/3000 loading...>>> 1100/3000 loading...>>> 1200/3000 loading...>>> 1300/3000 loading...>>> 1400/3000 loading...>>> 1500/3000 loading...>>> 1600/3000 loading...>>> 1700/3000 loading...>>> 1800/3000 loading...>>> 1900/3000 loading...>>> 2000/3000 loading...>>> 2100/3000 loading...>>> 2200/3000 loading...>>> 2300/3000 loading...>>> 2400/3000 loading...>>> 2500/3000 loading...>>> 2600/3000 loading...>>> 2700/3000 loading...>>> 2800/3000 loading...>>> 2900/3000 loading...>>> 3000/3000 loading...
>>> MLP dimensions: [20752, 256, 128, 128, 256, 5283].
>>> training MLP starts
training... 0100/100000: loss: 322.134training... 0200/100000: loss: 85.205training... 0300/100000: loss: 54.378training... 0400/100000: loss: 41.407training... 0500/100000: loss: 34.621training... 0600/100000: loss: 29.777training... 0700/100000: loss: 27.135training... 0800/100000: loss: 24.742training... 0900/100000: loss: 23.265training... 1000/100000: loss: 21.154training... 1100/100000: loss: 19.426training... 1200/100000: loss: 17.984training... 1300/100000: loss: 16.790training... 1400/100000: loss: 15.856training... 1500/100000: loss: 15.054training... 1600/100000: loss: 14.896training... 1700/100000: loss: 13.583training... 1800/100000: loss: 13.454training... 1900/100000: loss: 12.577training... 2000/100000: loss: 12.261training... 2100/100000: loss: 11.869training... 2200/100000: loss: 11.734training... 2300/100000: loss: 11.261training... 2400/100000: loss: 11.048training... 2500/100000: loss: 10.748training... 2600/100000: loss: 10.435training... 2700/100000: loss: 10.200training... 2800/100000: loss: 10.122training... 2900/100000: loss: 9.996training... 3000/100000: loss: 9.438training... 3100/100000: loss: 9.322training... 3200/100000: loss: 9.184training... 3300/100000: loss: 8.998training... 3400/100000: loss: 9.024training... 3500/100000: loss: 8.689training... 3600/100000: loss: 8.633training... 3700/100000: loss: 8.284training... 3800/100000: loss: 8.156training... 3900/100000: loss: 8.051training... 4000/100000: loss: 7.752training... 4100/100000: loss: 7.874training... 4200/100000: loss: 7.676training... 4300/100000: loss: 7.474training... 4400/100000: loss: 7.397training... 4500/100000: loss: 7.197training... 4600/100000: loss: 7.281training... 4700/100000: loss: 7.062training... 4800/100000: loss: 6.904training... 4900/100000: loss: 6.686training... 5000/100000: loss: 6.552training... 5100/100000: loss: 6.650training... 5200/100000: loss: 6.525training... 5300/100000: loss: 6.452training... 5400/100000: loss: 6.204training... 5500/100000: loss: 6.036training... 5600/100000: loss: 6.200training... 5700/100000: loss: 5.894training... 5800/100000: loss: 5.952training... 5900/100000: loss: 5.724training... 6000/100000: loss: 5.737training... 6100/100000: loss: 5.726training... 6200/100000: loss: 5.671training... 6300/100000: loss: 5.401training... 6400/100000: loss: 5.465training... 6500/100000: loss: 5.492training... 6600/100000: loss: 5.290training... 6700/100000: loss: 5.230training... 6800/100000: loss: 5.106training... 6900/100000: loss: 5.055training... 7000/100000: loss: 5.153training... 7100/100000: loss: 5.054training... 7200/100000: loss: 4.972training... 7300/100000: loss: 4.898training... 7400/100000: loss: 4.831training... 7500/100000: loss: 4.916training... 7600/100000: loss: 4.759training... 7700/100000: loss: 4.770training... 7800/100000: loss: 4.610training... 7900/100000: loss: 4.639training... 8000/100000: loss: 4.540training... 8100/100000: loss: 4.485training... 8200/100000: loss: 4.463training... 8300/100000: loss: 4.366training... 8400/100000: loss: 4.346training... 8500/100000: loss: 4.294training... 8600/100000: loss: 4.280training... 8700/100000: loss: 4.174training... 8800/100000: loss: 4.129training... 8900/100000: loss: 4.200training... 9000/100000: loss: 4.075training... 9100/100000: loss: 4.040training... 9200/100000: loss: 4.037training... 9300/100000: loss: 4.098training... 9400/100000: loss: 3.860training... 9500/100000: loss: 3.885training... 9600/100000: loss: 3.880training... 9700/100000: loss: 3.896training... 9800/100000: loss: 3.805training... 9900/100000: loss: 3.700training... 10000/100000: loss: 3.752training... 10100/100000: loss: 3.665training... 10200/100000: loss: 3.681training... 10300/100000: loss: 3.590training... 10400/100000: loss: 3.531training... 10500/100000: loss: 3.518training... 10600/100000: loss: 3.629training... 10700/100000: loss: 3.434training... 10800/100000: loss: 3.494training... 10900/100000: loss: 3.459training... 11000/100000: loss: 3.479training... 11100/100000: loss: 3.409training... 11200/100000: loss: 3.403training... 11300/100000: loss: 3.364training... 11400/100000: loss: 3.330training... 11500/100000: loss: 3.354training... 11600/100000: loss: 3.242training... 11700/100000: loss: 3.185training... 11800/100000: loss: 3.299training... 11900/100000: loss: 3.233training... 12000/100000: loss: 3.154training... 12100/100000: loss: 3.128training... 12200/100000: loss: 3.185training... 12300/100000: loss: 3.215training... 12400/100000: loss: 3.102training... 12500/100000: loss: 3.085training... 12600/100000: loss: 3.079training... 12700/100000: loss: 3.024training... 12800/100000: loss: 3.046training... 12900/100000: loss: 3.088training... 13000/100000: loss: 2.982training... 13100/100000: loss: 3.019training... 13200/100000: loss: 2.919training... 13300/100000: loss: 2.967training... 13400/100000: loss: 2.913training... 13500/100000: loss: 2.890training... 13600/100000: loss: 2.909training... 13700/100000: loss: 2.830training... 13800/100000: loss: 2.901training... 13900/100000: loss: 2.944training... 14000/100000: loss: 2.847training... 14100/100000: loss: 2.868training... 14200/100000: loss: 2.848training... 14300/100000: loss: 2.897training... 14400/100000: loss: 2.830training... 14500/100000: loss: 2.733training... 14600/100000: loss: 2.794training... 14700/100000: loss: 2.756training... 14800/100000: loss: 2.744training... 14900/100000: loss: 2.714training... 15000/100000: loss: 2.734training... 15100/100000: loss: 2.756training... 15200/100000: loss: 2.675training... 15300/100000: loss: 2.686training... 15400/100000: loss: 2.690training... 15500/100000: loss: 2.738training... 15600/100000: loss: 2.632training... 15700/100000: loss: 2.691training... 15800/100000: loss: 2.530training... 15900/100000: loss: 2.647training... 16000/100000: loss: 2.628training... 16100/100000: loss: 2.570training... 16200/100000: loss: 2.596training... 16300/100000: loss: 2.558training... 16400/100000: loss: 2.631training... 16500/100000: loss: 2.594training... 16600/100000: loss: 2.587training... 16700/100000: loss: 2.555training... 16800/100000: loss: 2.496training... 16900/100000: loss: 2.626training... 17000/100000: loss: 2.479training... 17100/100000: loss: 2.464training... 17200/100000: loss: 2.539training... 17300/100000: loss: 2.537training... 17400/100000: loss: 2.517training... 17500/100000: loss: 2.481training... 17600/100000: loss: 2.476training... 17700/100000: loss: 2.420training... 17800/100000: loss: 2.426training... 17900/100000: loss: 2.416training... 18000/100000: loss: 2.451training... 18100/100000: loss: 2.427training... 18200/100000: loss: 2.412training... 18300/100000: loss: 2.376training... 18400/100000: loss: 2.377training... 18500/100000: loss: 2.369training... 18600/100000: loss: 2.312training... 18700/100000: loss: 2.342training... 18800/100000: loss: 2.355training... 18900/100000: loss: 2.350training... 19000/100000: loss: 2.341training... 19100/100000: loss: 2.365training... 19200/100000: loss: 2.288training... 19300/100000: loss: 2.312training... 19400/100000: loss: 2.303training... 19500/100000: loss: 2.349training... 19600/100000: loss: 2.259training... 19700/100000: loss: 2.278training... 19800/100000: loss: 2.235training... 19900/100000: loss: 2.291training... 20000/100000: loss: 2.269training... 20100/100000: loss: 2.282training... 20200/100000: loss: 2.259training... 20300/100000: loss: 2.233training... 20400/100000: loss: 2.209training... 20500/100000: loss: 2.232training... 20600/100000: loss: 2.273training... 20700/100000: loss: 2.211training... 20800/100000: loss: 2.252training... 20900/100000: loss: 2.145training... 21000/100000: loss: 2.167training... 21100/100000: loss: 2.115training... 21200/100000: loss: 2.187training... 21300/100000: loss: 2.190training... 21400/100000: loss: 2.179training... 21500/100000: loss: 2.137training... 21600/100000: loss: 2.170training... 21700/100000: loss: 2.162training... 21800/100000: loss: 2.112training... 21900/100000: loss: 2.224training... 22000/100000: loss: 2.129training... 22100/100000: loss: 2.049training... 22200/100000: loss: 2.088training... 22300/100000: loss: 2.064training... 22400/100000: loss: 2.118training... 22500/100000: loss: 2.099training... 22600/100000: loss: 2.021training... 22700/100000: loss: 2.049training... 22800/100000: loss: 2.098training... 22900/100000: loss: 2.101training... 23000/100000: loss: 2.051training... 23100/100000: loss: 2.027training... 23200/100000: loss: 2.081training... 23300/100000: loss: 2.037training... 23400/100000: loss: 2.041training... 23500/100000: loss: 2.036training... 23600/100000: loss: 2.008training... 23700/100000: loss: 2.034training... 23800/100000: loss: 2.015training... 23900/100000: loss: 2.143training... 24000/100000: loss: 2.024training... 24100/100000: loss: 2.025training... 24200/100000: loss: 1.983training... 24300/100000: loss: 2.009training... 24400/100000: loss: 2.030training... 24500/100000: loss: 1.964training... 24600/100000: loss: 1.963training... 24700/100000: loss: 2.040training... 24800/100000: loss: 1.992training... 24900/100000: loss: 1.903training... 25000/100000: loss: 2.020training... 25100/100000: loss: 1.981training... 25200/100000: loss: 2.038training... 25300/100000: loss: 1.974training... 25400/100000: loss: 1.941training... 25500/100000: loss: 1.962training... 25600/100000: loss: 1.906training... 25700/100000: loss: 1.930training... 25800/100000: loss: 1.890training... 25900/100000: loss: 1.901training... 26000/100000: loss: 1.906training... 26100/100000: loss: 1.890training... 26200/100000: loss: 1.917training... 26300/100000: loss: 1.938training... 26400/100000: loss: 1.926training... 26500/100000: loss: 1.845training... 26600/100000: loss: 1.902training... 26700/100000: loss: 1.883training... 26800/100000: loss: 1.859training... 26900/100000: loss: 1.862training... 27000/100000: loss: 1.819training... 27100/100000: loss: 1.835training... 27200/100000: loss: 1.794training... 27300/100000: loss: 1.868training... 27400/100000: loss: 1.864training... 27500/100000: loss: 1.882training... 27600/100000: loss: 1.842training... 27700/100000: loss: 1.866training... 27800/100000: loss: 1.843training... 27900/100000: loss: 1.850training... 28000/100000: loss: 1.838training... 28100/100000: loss: 1.844training... 28200/100000: loss: 1.852training... 28300/100000: loss: 1.804training... 28400/100000: loss: 1.820training... 28500/100000: loss: 1.856training... 28600/100000: loss: 1.825training... 28700/100000: loss: 1.860training... 28800/100000: loss: 1.758training... 28900/100000: loss: 1.736training... 29000/100000: loss: 1.846training... 29100/100000: loss: 1.777training... 29200/100000: loss: 1.769training... 29300/100000: loss: 1.867training... 29400/100000: loss: 1.788training... 29500/100000: loss: 1.776training... 29600/100000: loss: 1.799training... 29700/100000: loss: 1.715training... 29800/100000: loss: 1.791training... 29900/100000: loss: 1.810training... 30000/100000: loss: 1.801training... 30100/100000: loss: 1.817training... 30200/100000: loss: 1.791training... 30300/100000: loss: 1.690training... 30400/100000: loss: 1.748training... 30500/100000: loss: 1.804training... 30600/100000: loss: 1.795training... 30700/100000: loss: 1.732training... 30800/100000: loss: 1.698training... 30900/100000: loss: 1.733training... 31000/100000: loss: 1.735training... 31100/100000: loss: 1.716training... 31200/100000: loss: 1.732training... 31300/100000: loss: 1.729training... 31400/100000: loss: 1.715training... 31500/100000: loss: 1.749training... 31600/100000: loss: 1.704training... 31700/100000: loss: 1.705training... 31800/100000: loss: 1.732training... 31900/100000: loss: 1.749training... 32000/100000: loss: 1.770training... 32100/100000: loss: 1.769training... 32200/100000: loss: 1.699training... 32300/100000: loss: 1.735training... 32400/100000: loss: 1.675training... 32500/100000: loss: 1.723training... 32600/100000: loss: 1.726training... 32700/100000: loss: 1.698training... 32800/100000: loss: 1.692training... 32900/100000: loss: 1.713training... 33000/100000: loss: 1.683training... 33100/100000: loss: 1.740training... 33200/100000: loss: 1.699training... 33300/100000: loss: 1.715training... 33400/100000: loss: 1.675training... 33500/100000: loss: 1.676training... 33600/100000: loss: 1.670training... 33700/100000: loss: 1.669training... 33800/100000: loss: 1.768training... 33900/100000: loss: 1.648training... 34000/100000: loss: 1.655training... 34100/100000: loss: 1.712training... 34200/100000: loss: 1.603training... 34300/100000: loss: 1.636training... 34400/100000: loss: 1.647training... 34500/100000: loss: 1.634training... 34600/100000: loss: 1.623training... 34700/100000: loss: 1.648training... 34800/100000: loss: 1.620training... 34900/100000: loss: 1.594training... 35000/100000: loss: 1.641training... 35100/100000: loss: 1.656training... 35200/100000: loss: 1.628training... 35300/100000: loss: 1.720training... 35400/100000: loss: 1.628training... 35500/100000: loss: 1.629training... 35600/100000: loss: 1.583training... 35700/100000: loss: 1.639training... 35800/100000: loss: 1.688training... 35900/100000: loss: 1.617training... 36000/100000: loss: 1.631training... 36100/100000: loss: 1.616training... 36200/100000: loss: 1.586training... 36300/100000: loss: 1.595training... 36400/100000: loss: 1.626training... 36500/100000: loss: 1.606training... 36600/100000: loss: 1.607training... 36700/100000: loss: 1.640training... 36800/100000: loss: 1.597training... 36900/100000: loss: 1.638training... 37000/100000: loss: 1.571training... 37100/100000: loss: 1.593training... 37200/100000: loss: 1.600training... 37300/100000: loss: 1.590training... 37400/100000: loss: 1.608training... 37500/100000: loss: 1.620training... 37600/100000: loss: 1.587training... 37700/100000: loss: 1.624training... 37800/100000: loss: 1.620training... 37900/100000: loss: 1.562training... 38000/100000: loss: 1.564training... 38100/100000: loss: 1.592training... 38200/100000: loss: 1.560training... 38300/100000: loss: 1.590training... 38400/100000: loss: 1.557training... 38500/100000: loss: 1.616training... 38600/100000: loss: 1.559training... 38700/100000: loss: 1.566training... 38800/100000: loss: 1.558training... 38900/100000: loss: 1.618training... 39000/100000: loss: 1.569training... 39100/100000: loss: 1.567training... 39200/100000: loss: 1.564training... 39300/100000: loss: 1.517training... 39400/100000: loss: 1.563training... 39500/100000: loss: 1.577training... 39600/100000: loss: 1.605training... 39700/100000: loss: 1.538training... 39800/100000: loss: 1.509training... 39900/100000: loss: 1.515training... 40000/100000: loss: 1.568training... 40100/100000: loss: 1.555training... 40200/100000: loss: 1.561training... 40300/100000: loss: 1.506training... 40400/100000: loss: 1.552training... 40500/100000: loss: 1.559training... 40600/100000: loss: 1.545training... 40700/100000: loss: 1.517training... 40800/100000: loss: 1.516training... 40900/100000: loss: 1.482training... 41000/100000: loss: 1.537training... 41100/100000: loss: 1.562training... 41200/100000: loss: 1.547training... 41300/100000: loss: 1.503training... 41400/100000: loss: 1.562training... 41500/100000: loss: 1.531training... 41600/100000: loss: 1.531training... 41700/100000: loss: 1.551training... 41800/100000: loss: 1.511training... 41900/100000: loss: 1.542training... 42000/100000: loss: 1.498training... 42100/100000: loss: 1.484training... 42200/100000: loss: 1.539training... 42300/100000: loss: 1.524training... 42400/100000: loss: 1.497training... 42500/100000: loss: 1.578training... 42600/100000: loss: 1.501training... 42700/100000: loss: 1.516training... 42800/100000: loss: 1.499training... 42900/100000: loss: 1.497training... 43000/100000: loss: 1.506training... 43100/100000: loss: 1.490training... 43200/100000: loss: 1.491training... 43300/100000: loss: 1.505training... 43400/100000: loss: 1.523training... 43500/100000: loss: 1.563training... 43600/100000: loss: 1.480training... 43700/100000: loss: 1.497training... 43800/100000: loss: 1.475training... 43900/100000: loss: 1.539training... 44000/100000: loss: 1.450training... 44100/100000: loss: 1.499training... 44200/100000: loss: 1.497training... 44300/100000: loss: 1.517training... 44400/100000: loss: 1.487training... 44500/100000: loss: 1.503training... 44600/100000: loss: 1.504training... 44700/100000: loss: 1.483training... 44800/100000: loss: 1.485training... 44900/100000: loss: 1.471training... 45000/100000: loss: 1.481training... 45100/100000: loss: 1.449training... 45200/100000: loss: 1.472training... 45300/100000: loss: 1.482training... 45400/100000: loss: 1.480training... 45500/100000: loss: 1.450training... 45600/100000: loss: 1.452training... 45700/100000: loss: 1.488training... 45800/100000: loss: 1.445training... 45900/100000: loss: 1.505training... 46000/100000: loss: 1.501training... 46100/100000: loss: 1.447training... 46200/100000: loss: 1.486training... 46300/100000: loss: 1.506training... 46400/100000: loss: 1.468training... 46500/100000: loss: 1.485training... 46600/100000: loss: 1.412training... 46700/100000: loss: 1.455training... 46800/100000: loss: 1.449training... 46900/100000: loss: 1.443training... 47000/100000: loss: 1.443training... 47100/100000: loss: 1.473training... 47200/100000: loss: 1.446training... 47300/100000: loss: 1.452training... 47400/100000: loss: 1.460training... 47500/100000: loss: 1.439training... 47600/100000: loss: 1.462training... 47700/100000: loss: 1.454training... 47800/100000: loss: 1.386training... 47900/100000: loss: 1.511training... 48000/100000: loss: 1.435training... 48100/100000: loss: 1.447training... 48200/100000: loss: 1.482training... 48300/100000: loss: 1.422training... 48400/100000: loss: 1.497training... 48500/100000: loss: 1.432training... 48600/100000: loss: 1.440training... 48700/100000: loss: 1.489training... 48800/100000: loss: 1.461training... 48900/100000: loss: 1.453training... 49000/100000: loss: 1.480training... 49100/100000: loss: 1.431training... 49200/100000: loss: 1.421training... 49300/100000: loss: 1.445training... 49400/100000: loss: 1.411training... 49500/100000: loss: 1.416training... 49600/100000: loss: 1.445training... 49700/100000: loss: 1.411training... 49800/100000: loss: 1.430training... 49900/100000: loss: 1.422training... 50000/100000: loss: 1.419training... 50100/100000: loss: 1.466training... 50200/100000: loss: 1.446training... 50300/100000: loss: 1.427training... 50400/100000: loss: 1.462training... 50500/100000: loss: 1.488training... 50600/100000: loss: 1.420training... 50700/100000: loss: 1.411training... 50800/100000: loss: 1.487training... 50900/100000: loss: 1.395training... 51000/100000: loss: 1.426training... 51100/100000: loss: 1.447training... 51200/100000: loss: 1.424training... 51300/100000: loss: 1.469training... 51400/100000: loss: 1.416training... 51500/100000: loss: 1.378training... 51600/100000: loss: 1.425training... 51700/100000: loss: 1.396training... 51800/100000: loss: 1.360training... 51900/100000: loss: 1.412training... 52000/100000: loss: 1.395training... 52100/100000: loss: 1.404training... 52200/100000: loss: 1.391training... 52300/100000: loss: 1.424training... 52400/100000: loss: 1.383training... 52500/100000: loss: 1.378training... 52600/100000: loss: 1.385training... 52700/100000: loss: 1.391training... 52800/100000: loss: 1.399training... 52900/100000: loss: 1.386training... 53000/100000: loss: 1.394training... 53100/100000: loss: 1.397training... 53200/100000: loss: 1.383training... 53300/100000: loss: 1.392training... 53400/100000: loss: 1.372training... 53500/100000: loss: 1.411training... 53600/100000: loss: 1.386training... 53700/100000: loss: 1.391training... 53800/100000: loss: 1.418training... 53900/100000: loss: 1.423training... 54000/100000: loss: 1.395training... 54100/100000: loss: 1.382training... 54200/100000: loss: 1.397training... 54300/100000: loss: 1.405training... 54400/100000: loss: 1.373training... 54500/100000: loss: 1.407training... 54600/100000: loss: 1.380training... 54700/100000: loss: 1.400training... 54800/100000: loss: 1.399training... 54900/100000: loss: 1.383training... 55000/100000: loss: 1.427training... 55100/100000: loss: 1.410training... 55200/100000: loss: 1.426training... 55300/100000: loss: 1.416training... 55400/100000: loss: 1.384training... 55500/100000: loss: 1.353training... 55600/100000: loss: 1.412training... 55700/100000: loss: 1.399training... 55800/100000: loss: 1.434training... 55900/100000: loss: 1.442training... 56000/100000: loss: 1.401training... 56100/100000: loss: 1.445training... 56200/100000: loss: 1.391training... 56300/100000: loss: 1.413training... 56400/100000: loss: 1.397training... 56500/100000: loss: 1.355training... 56600/100000: loss: 1.395training... 56700/100000: loss: 1.365training... 56800/100000: loss: 1.413training... 56900/100000: loss: 1.324training... 57000/100000: loss: 1.338training... 57100/100000: loss: 1.378training... 57200/100000: loss: 1.353training... 57300/100000: loss: 1.440training... 57400/100000: loss: 1.346training... 57500/100000: loss: 1.368training... 57600/100000: loss: 1.393training... 57700/100000: loss: 1.333training... 57800/100000: loss: 1.328training... 57900/100000: loss: 1.354training... 58000/100000: loss: 1.417training... 58100/100000: loss: 1.337training... 58200/100000: loss: 1.361training... 58300/100000: loss: 1.337training... 58400/100000: loss: 1.409training... 58500/100000: loss: 1.364training... 58600/100000: loss: 1.354training... 58700/100000: loss: 1.378training... 58800/100000: loss: 1.400training... 58900/100000: loss: 1.347training... 59000/100000: loss: 1.385training... 59100/100000: loss: 1.360training... 59200/100000: loss: 1.349training... 59300/100000: loss: 1.347training... 59400/100000: loss: 1.359training... 59500/100000: loss: 1.350training... 59600/100000: loss: 1.336training... 59700/100000: loss: 1.360training... 59800/100000: loss: 1.336training... 59900/100000: loss: 1.344training... 60000/100000: loss: 1.373training... 60100/100000: loss: 1.322training... 60200/100000: loss: 1.311training... 60300/100000: loss: 1.334training... 60400/100000: loss: 1.345training... 60500/100000: loss: 1.444training... 60600/100000: loss: 1.288training... 60700/100000: loss: 1.376training... 60800/100000: loss: 1.307training... 60900/100000: loss: 1.397training... 61000/100000: loss: 1.279training... 61100/100000: loss: 1.293training... 61200/100000: loss: 1.355training... 61300/100000: loss: 1.362training... 61400/100000: loss: 1.345training... 61500/100000: loss: 1.375training... 61600/100000: loss: 1.380training... 61700/100000: loss: 1.371training... 61800/100000: loss: 1.351training... 61900/100000: loss: 1.341training... 62000/100000: loss: 1.379training... 62100/100000: loss: 1.325training... 62200/100000: loss: 1.332training... 62300/100000: loss: 1.388training... 62400/100000: loss: 1.334training... 62500/100000: loss: 1.310training... 62600/100000: loss: 1.384training... 62700/100000: loss: 1.288training... 62800/100000: loss: 1.368training... 62900/100000: loss: 1.350training... 63000/100000: loss: 1.324training... 63100/100000: loss: 1.314training... 63200/100000: loss: 1.346training... 63300/100000: loss: 1.303training... 63400/100000: loss: 1.339training... 63500/100000: loss: 1.333training... 63600/100000: loss: 1.341training... 63700/100000: loss: 1.345training... 63800/100000: loss: 1.365training... 63900/100000: loss: 1.321training... 64000/100000: loss: 1.290training... 64100/100000: loss: 1.293training... 64200/100000: loss: 1.326training... 64300/100000: loss: 1.377training... 64400/100000: loss: 1.329training... 64500/100000: loss: 1.339training... 64600/100000: loss: 1.327training... 64700/100000: loss: 1.329training... 64800/100000: loss: 1.338training... 64900/100000: loss: 1.309training... 65000/100000: loss: 1.290training... 65100/100000: loss: 1.350training... 65200/100000: loss: 1.383training... 65300/100000: loss: 1.307training... 65400/100000: loss: 1.338training... 65500/100000: loss: 1.315training... 65600/100000: loss: 1.308training... 65700/100000: loss: 1.286training... 65800/100000: loss: 1.335training... 65900/100000: loss: 1.398training... 66000/100000: loss: 1.312training... 66100/100000: loss: 1.335training... 66200/100000: loss: 1.321training... 66300/100000: loss: 1.322training... 66400/100000: loss: 1.332training... 66500/100000: loss: 1.276training... 66600/100000: loss: 1.326training... 66700/100000: loss: 1.327training... 66800/100000: loss: 1.325training... 66900/100000: loss: 1.323training... 67000/100000: loss: 1.313training... 67100/100000: loss: 1.280training... 67200/100000: loss: 1.327training... 67300/100000: loss: 1.324training... 67400/100000: loss: 1.304training... 67500/100000: loss: 1.362training... 67600/100000: loss: 1.305training... 67700/100000: loss: 1.305training... 67800/100000: loss: 1.311training... 67900/100000: loss: 1.318training... 68000/100000: loss: 1.297training... 68100/100000: loss: 1.286training... 68200/100000: loss: 1.306training... 68300/100000: loss: 1.308training... 68400/100000: loss: 1.297training... 68500/100000: loss: 1.339training... 68600/100000: loss: 1.315training... 68700/100000: loss: 1.321training... 68800/100000: loss: 1.315training... 68900/100000: loss: 1.337training... 69000/100000: loss: 1.338training... 69100/100000: loss: 1.367training... 69200/100000: loss: 1.285training... 69300/100000: loss: 1.268training... 69400/100000: loss: 1.307training... 69500/100000: loss: 1.267training... 69600/100000: loss: 1.318training... 69700/100000: loss: 1.310training... 69800/100000: loss: 1.315training... 69900/100000: loss: 1.300training... 70000/100000: loss: 1.322training... 70100/100000: loss: 1.305training... 70200/100000: loss: 1.325training... 70300/100000: loss: 1.291training... 70400/100000: loss: 1.314training... 70500/100000: loss: 1.290training... 70600/100000: loss: 1.353training... 70700/100000: loss: 1.299training... 70800/100000: loss: 1.310training... 70900/100000: loss: 1.288training... 71000/100000: loss: 1.269training... 71100/100000: loss: 1.304training... 71200/100000: loss: 1.276training... 71300/100000: loss: 1.303training... 71400/100000: loss: 1.267training... 71500/100000: loss: 1.290training... 71600/100000: loss: 1.266training... 71700/100000: loss: 1.298training... 71800/100000: loss: 1.291training... 71900/100000: loss: 1.298training... 72000/100000: loss: 1.279training... 72100/100000: loss: 1.351training... 72200/100000: loss: 1.277training... 72300/100000: loss: 1.256training... 72400/100000: loss: 1.288training... 72500/100000: loss: 1.281training... 72600/100000: loss: 1.323training... 72700/100000: loss: 1.340training... 72800/100000: loss: 1.264training... 72900/100000: loss: 1.269training... 73000/100000: loss: 1.270training... 73100/100000: loss: 1.297training... 73200/100000: loss: 1.381training... 73300/100000: loss: 1.284training... 73400/100000: loss: 1.296training... 73500/100000: loss: 1.286training... 73600/100000: loss: 1.281training... 73700/100000: loss: 1.334training... 73800/100000: loss: 1.333training... 73900/100000: loss: 1.246training... 74000/100000: loss: 1.286training... 74100/100000: loss: 1.251training... 74200/100000: loss: 1.310training... 74300/100000: loss: 1.303training... 74400/100000: loss: 1.281training... 74500/100000: loss: 1.289training... 74600/100000: loss: 1.300training... 74700/100000: loss: 1.322training... 74800/100000: loss: 1.287training... 74900/100000: loss: 1.272training... 75000/100000: loss: 1.293training... 75100/100000: loss: 1.345training... 75200/100000: loss: 1.252training... 75300/100000: loss: 1.263training... 75400/100000: loss: 1.308training... 75500/100000: loss: 1.328training... 75600/100000: loss: 1.339training... 75700/100000: loss: 1.263training... 75800/100000: loss: 1.299training... 75900/100000: loss: 1.304training... 76000/100000: loss: 1.265training... 76100/100000: loss: 1.285training... 76200/100000: loss: 1.245training... 76300/100000: loss: 1.268training... 76400/100000: loss: 1.239training... 76500/100000: loss: 1.289training... 76600/100000: loss: 1.280training... 76700/100000: loss: 1.364training... 76800/100000: loss: 1.277training... 76900/100000: loss: 1.247training... 77000/100000: loss: 1.261training... 77100/100000: loss: 1.249training... 77200/100000: loss: 1.275training... 77300/100000: loss: 1.294training... 77400/100000: loss: 1.351training... 77500/100000: loss: 1.267training... 77600/100000: loss: 1.286training... 77700/100000: loss: 1.284training... 77800/100000: loss: 1.286training... 77900/100000: loss: 1.321training... 78000/100000: loss: 1.306training... 78100/100000: loss: 1.245training... 78200/100000: loss: 1.267training... 78300/100000: loss: 1.262training... 78400/100000: loss: 1.260training... 78500/100000: loss: 1.236training... 78600/100000: loss: 1.273training... 78700/100000: loss: 1.251training... 78800/100000: loss: 1.289training... 78900/100000: loss: 1.324training... 79000/100000: loss: 1.266training... 79100/100000: loss: 1.233training... 79200/100000: loss: 1.228training... 79300/100000: loss: 1.304training... 79400/100000: loss: 1.261training... 79500/100000: loss: 1.218training... 79600/100000: loss: 1.264training... 79700/100000: loss: 1.217training... 79800/100000: loss: 1.260training... 79900/100000: loss: 1.267training... 80000/100000: loss: 1.247training... 80100/100000: loss: 1.267training... 80200/100000: loss: 1.257training... 80300/100000: loss: 1.229training... 80400/100000: loss: 1.220training... 80500/100000: loss: 1.261training... 80600/100000: loss: 1.301training... 80700/100000: loss: 1.274training... 80800/100000: loss: 1.252training... 80900/100000: loss: 1.281training... 81000/100000: loss: 1.250training... 81100/100000: loss: 1.243training... 81200/100000: loss: 1.292training... 81300/100000: loss: 1.255training... 81400/100000: loss: 1.210training... 81500/100000: loss: 1.236training... 81600/100000: loss: 1.251training... 81700/100000: loss: 1.268training... 81800/100000: loss: 1.199training... 81900/100000: loss: 1.228training... 82000/100000: loss: 1.227training... 82100/100000: loss: 1.248training... 82200/100000: loss: 1.293training... 82300/100000: loss: 1.235training... 82400/100000: loss: 1.262training... 82500/100000: loss: 1.248training... 82600/100000: loss: 1.217training... 82700/100000: loss: 1.265training... 82800/100000: loss: 1.265training... 82900/100000: loss: 1.233training... 83000/100000: loss: 1.214training... 83100/100000: loss: 1.240training... 83200/100000: loss: 1.242training... 83300/100000: loss: 1.242training... 83400/100000: loss: 1.250training... 83500/100000: loss: 1.238training... 83600/100000: loss: 1.259training... 83700/100000: loss: 1.253training... 83800/100000: loss: 1.259training... 83900/100000: loss: 1.288training... 84000/100000: loss: 1.226training... 84100/100000: loss: 1.265training... 84200/100000: loss: 1.206training... 84300/100000: loss: 1.297training... 84400/100000: loss: 1.259training... 84500/100000: loss: 1.229training... 84600/100000: loss: 1.232training... 84700/100000: loss: 1.233training... 84800/100000: loss: 1.255training... 84900/100000: loss: 1.250training... 85000/100000: loss: 1.235training... 85100/100000: loss: 1.231training... 85200/100000: loss: 1.237training... 85300/100000: loss: 1.248training... 85400/100000: loss: 1.258training... 85500/100000: loss: 1.234training... 85600/100000: loss: 1.257training... 85700/100000: loss: 1.213training... 85800/100000: loss: 1.229training... 85900/100000: loss: 1.230training... 86000/100000: loss: 1.197training... 86100/100000: loss: 1.243training... 86200/100000: loss: 1.261training... 86300/100000: loss: 1.239training... 86400/100000: loss: 1.248training... 86500/100000: loss: 1.277training... 86600/100000: loss: 1.211training... 86700/100000: loss: 1.229training... 86800/100000: loss: 1.208training... 86900/100000: loss: 1.219training... 87000/100000: loss: 1.206training... 87100/100000: loss: 1.246training... 87200/100000: loss: 1.215training... 87300/100000: loss: 1.220training... 87400/100000: loss: 1.273training... 87500/100000: loss: 1.224training... 87600/100000: loss: 1.235training... 87700/100000: loss: 1.252training... 87800/100000: loss: 1.196training... 87900/100000: loss: 1.211training... 88000/100000: loss: 1.285training... 88100/100000: loss: 1.231training... 88200/100000: loss: 1.221training... 88300/100000: loss: 1.206training... 88400/100000: loss: 1.197training... 88500/100000: loss: 1.254training... 88600/100000: loss: 1.230training... 88700/100000: loss: 1.205training... 88800/100000: loss: 1.184training... 88900/100000: loss: 1.260training... 89000/100000: loss: 1.202training... 89100/100000: loss: 1.204training... 89200/100000: loss: 1.211training... 89300/100000: loss: 1.234training... 89400/100000: loss: 1.223training... 89500/100000: loss: 1.207training... 89600/100000: loss: 1.240training... 89700/100000: loss: 1.245training... 89800/100000: loss: 1.227training... 89900/100000: loss: 1.273training... 90000/100000: loss: 1.214training... 90100/100000: loss: 1.229training... 90200/100000: loss: 1.183training... 90300/100000: loss: 1.252training... 90400/100000: loss: 1.231training... 90500/100000: loss: 1.189training... 90600/100000: loss: 1.238training... 90700/100000: loss: 1.206training... 90800/100000: loss: 1.214training... 90900/100000: loss: 1.216training... 91000/100000: loss: 1.225training... 91100/100000: loss: 1.203training... 91200/100000: loss: 1.264training... 91300/100000: loss: 1.213training... 91400/100000: loss: 1.241training... 91500/100000: loss: 1.213training... 91600/100000: loss: 1.203training... 91700/100000: loss: 1.271training... 91800/100000: loss: 1.254training... 91900/100000: loss: 1.260training... 92000/100000: loss: 1.255training... 92100/100000: loss: 1.209training... 92200/100000: loss: 1.220training... 92300/100000: loss: 1.230training... 92400/100000: loss: 1.231training... 92500/100000: loss: 1.198training... 92600/100000: loss: 1.202training... 92700/100000: loss: 1.238training... 92800/100000: loss: 1.256training... 92900/100000: loss: 1.215training... 93000/100000: loss: 1.254training... 93100/100000: loss: 1.217training... 93200/100000: loss: 1.225training... 93300/100000: loss: 1.236training... 93400/100000: loss: 1.196training... 93500/100000: loss: 1.188training... 93600/100000: loss: 1.223training... 93700/100000: loss: 1.197training... 93800/100000: loss: 1.285training... 93900/100000: loss: 1.241training... 94000/100000: loss: 1.212training... 94100/100000: loss: 1.240training... 94200/100000: loss: 1.262training... 94300/100000: loss: 1.191training... 94400/100000: loss: 1.179training... 94500/100000: loss: 1.237training... 94600/100000: loss: 1.232training... 94700/100000: loss: 1.211training... 94800/100000: loss: 1.164training... 94900/100000: loss: 1.211training... 95000/100000: loss: 1.261training... 95100/100000: loss: 1.211training... 95200/100000: loss: 1.197training... 95300/100000: loss: 1.215training... 95400/100000: loss: 1.219training... 95500/100000: loss: 1.199training... 95600/100000: loss: 1.196training... 95700/100000: loss: 1.198training... 95800/100000: loss: 1.225training... 95900/100000: loss: 1.215training... 96000/100000: loss: 1.197training... 96100/100000: loss: 1.222training... 96200/100000: loss: 1.210training... 96300/100000: loss: 1.224training... 96400/100000: loss: 1.195training... 96500/100000: loss: 1.203training... 96600/100000: loss: 1.249training... 96700/100000: loss: 1.222training... 96800/100000: loss: 1.200training... 96900/100000: loss: 1.184training... 97000/100000: loss: 1.212training... 97100/100000: loss: 1.258training... 97200/100000: loss: 1.207training... 97300/100000: loss: 1.228training... 97400/100000: loss: 1.211training... 97500/100000: loss: 1.225training... 97600/100000: loss: 1.212training... 97700/100000: loss: 1.211training... 97800/100000: loss: 1.204training... 97900/100000: loss: 1.192training... 98000/100000: loss: 1.214training... 98100/100000: loss: 1.207training... 98200/100000: loss: 1.207training... 98300/100000: loss: 1.209training... 98400/100000: loss: 1.179training... 98500/100000: loss: 1.240training... 98600/100000: loss: 1.236training... 98700/100000: loss: 1.194training... 98800/100000: loss: 1.212training... 98900/100000: loss: 1.219training... 99000/100000: loss: 1.219training... 99100/100000: loss: 1.232training... 99200/100000: loss: 1.201training... 99300/100000: loss: 1.193training... 99400/100000: loss: 1.204training... 99500/100000: loss: 1.199training... 99600/100000: loss: 1.190training... 99700/100000: loss: 1.188training... 99800/100000: loss: 1.190training... 99900/100000: loss: 1.201training... 100000/100000: loss: 1.210
>>> It elapsed 45303.55 seconds for training
>>> Star initialized.
>>> Draping...
>>> It takes 4.233 ms for draping
>>> OBJ file [./example/pose_0_10.obj] save completed.
>>> Draping...
>>> It takes 2.647 ms for draping
>>> OBJ file [./example/pose_1_10.obj] save completed.
>>> Draping...
>>> It takes 2.662 ms for draping
>>> OBJ file [./example/pose_2_10.obj] save completed.
>>> Draping...
>>> It takes 2.681 ms for draping
>>> OBJ file [./example/pose_3_10.obj] save completed.
>>> Draping...
>>> It takes 2.652 ms for draping
>>> OBJ file [./example/pose_4_10.obj] save completed.
>>> Draping...
>>> It takes 2.677 ms for draping
>>> OBJ file [./example/pose_5_10.obj] save completed.
>>> Draping...
>>> It takes 2.720 ms for draping
>>> OBJ file [./example/pose_6_10.obj] save completed.
>>> Draping...
>>> It takes 2.645 ms for draping
>>> OBJ file [./example/pose_7_10.obj] save completed.
>>> Draping...
>>> It takes 2.646 ms for draping
>>> OBJ file [./example/pose_8_10.obj] save completed.
>>> Draping...
>>> It takes 2.664 ms for draping
>>> OBJ file [./example/pose_9_10.obj] save completed.
>>> Draping...
>>> It takes 2.660 ms for draping
>>> OBJ file [./example/pose_10_10.obj] save completed.
