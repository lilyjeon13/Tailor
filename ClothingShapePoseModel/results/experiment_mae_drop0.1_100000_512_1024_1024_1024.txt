>>> Initializing clothing shape model...
>>> Star initialized.
>>> Get parameters list...
>>> Length of pose: 150
>>> Length of shape: 20
>>> Length of data: 3000
>>> 100/3000 loading...>>> 200/3000 loading...>>> 300/3000 loading...>>> 400/3000 loading...>>> 500/3000 loading...>>> 600/3000 loading...>>> 700/3000 loading...>>> 800/3000 loading...>>> 900/3000 loading...>>> 1000/3000 loading...>>> 1100/3000 loading...>>> 1200/3000 loading...>>> 1300/3000 loading...>>> 1400/3000 loading...>>> 1500/3000 loading...>>> 1600/3000 loading...>>> 1700/3000 loading...>>> 1800/3000 loading...>>> 1900/3000 loading...>>> 2000/3000 loading...>>> 2100/3000 loading...>>> 2200/3000 loading...>>> 2300/3000 loading...>>> 2400/3000 loading...>>> 2500/3000 loading...>>> 2600/3000 loading...>>> 2700/3000 loading...>>> 2800/3000 loading...>>> 2900/3000 loading...>>> 3000/3000 loading...
>>> MLP dimensions: [20752, 512, 1024, 1024, 1024, 5283].
>>> training MLP starts
training... 0100/100000: loss: 324.773training... 0200/100000: loss: 273.965training... 0300/100000: loss: 240.048training... 0400/100000: loss: 207.985training... 0500/100000: loss: 185.839training... 0600/100000: loss: 172.804training... 0700/100000: loss: 153.895training... 0800/100000: loss: 146.186training... 0900/100000: loss: 140.349training... 1000/100000: loss: 134.733training... 1100/100000: loss: 131.404training... 1200/100000: loss: 125.151training... 1300/100000: loss: 121.569training... 1400/100000: loss: 118.709training... 1500/100000: loss: 117.347training... 1600/100000: loss: 113.134training... 1700/100000: loss: 111.304training... 1800/100000: loss: 109.332training... 1900/100000: loss: 107.213training... 2000/100000: loss: 104.895training... 2100/100000: loss: 103.268training... 2200/100000: loss: 101.855training... 2300/100000: loss: 100.656training... 2400/100000: loss: 98.162training... 2500/100000: loss: 96.155training... 2600/100000: loss: 95.639training... 2700/100000: loss: 93.952training... 2800/100000: loss: 93.396training... 2900/100000: loss: 91.254training... 3000/100000: loss: 91.095training... 3100/100000: loss: 90.421training... 3200/100000: loss: 88.773training... 3300/100000: loss: 87.343training... 3400/100000: loss: 86.490training... 3500/100000: loss: 85.822training... 3600/100000: loss: 85.658training... 3700/100000: loss: 84.366training... 3800/100000: loss: 82.817training... 3900/100000: loss: 83.492training... 4000/100000: loss: 81.946training... 4100/100000: loss: 81.918training... 4200/100000: loss: 80.143training... 4300/100000: loss: 79.214training... 4400/100000: loss: 79.367training... 4500/100000: loss: 77.951training... 4600/100000: loss: 77.966training... 4700/100000: loss: 77.280training... 4800/100000: loss: 77.305training... 4900/100000: loss: 75.953training... 5000/100000: loss: 75.228training... 5100/100000: loss: 74.578training... 5200/100000: loss: 74.182training... 5300/100000: loss: 73.450training... 5400/100000: loss: 72.829training... 5500/100000: loss: 72.463training... 5600/100000: loss: 71.836training... 5700/100000: loss: 71.994training... 5800/100000: loss: 71.057training... 5900/100000: loss: 70.859training... 6000/100000: loss: 70.046training... 6100/100000: loss: 69.444training... 6200/100000: loss: 70.585training... 6300/100000: loss: 68.602training... 6400/100000: loss: 68.574training... 6500/100000: loss: 67.786training... 6600/100000: loss: 66.898training... 6700/100000: loss: 66.523training... 6800/100000: loss: 66.060training... 6900/100000: loss: 65.821training... 7000/100000: loss: 65.832training... 7100/100000: loss: 65.559training... 7200/100000: loss: 64.891training... 7300/100000: loss: 65.380training... 7400/100000: loss: 65.048training... 7500/100000: loss: 65.120training... 7600/100000: loss: 63.865training... 7700/100000: loss: 64.043training... 7800/100000: loss: 64.265training... 7900/100000: loss: 63.838training... 8000/100000: loss: 63.512training... 8100/100000: loss: 62.610training... 8200/100000: loss: 62.931training... 8300/100000: loss: 62.556training... 8400/100000: loss: 62.523training... 8500/100000: loss: 62.080training... 8600/100000: loss: 62.491training... 8700/100000: loss: 61.680training... 8800/100000: loss: 61.239training... 8900/100000: loss: 61.885training... 9000/100000: loss: 60.104training... 9100/100000: loss: 60.960training... 9200/100000: loss: 60.964training... 9300/100000: loss: 60.060training... 9400/100000: loss: 59.516training... 9500/100000: loss: 59.175training... 9600/100000: loss: 59.175training... 9700/100000: loss: 59.219training... 9800/100000: loss: 59.481training... 9900/100000: loss: 59.042training... 10000/100000: loss: 59.337training... 10100/100000: loss: 59.034training... 10200/100000: loss: 59.083training... 10300/100000: loss: 59.061training... 10400/100000: loss: 58.567training... 10500/100000: loss: 58.059training... 10600/100000: loss: 57.523training... 10700/100000: loss: 57.260training... 10800/100000: loss: 57.915training... 10900/100000: loss: 57.486training... 11000/100000: loss: 57.259training... 11100/100000: loss: 56.692training... 11200/100000: loss: 56.396training... 11300/100000: loss: 55.864training... 11400/100000: loss: 56.676training... 11500/100000: loss: 57.422training... 11600/100000: loss: 56.380training... 11700/100000: loss: 55.846training... 11800/100000: loss: 56.043training... 11900/100000: loss: 55.668training... 12000/100000: loss: 55.247training... 12100/100000: loss: 55.589training... 12200/100000: loss: 55.169training... 12300/100000: loss: 55.404training... 12400/100000: loss: 55.294training... 12500/100000: loss: 54.916training... 12600/100000: loss: 54.769training... 12700/100000: loss: 54.788training... 12800/100000: loss: 54.522training... 12900/100000: loss: 54.052training... 13000/100000: loss: 54.488training... 13100/100000: loss: 54.443training... 13200/100000: loss: 53.880training... 13300/100000: loss: 54.374training... 13400/100000: loss: 53.736training... 13500/100000: loss: 53.851training... 13600/100000: loss: 53.870training... 13700/100000: loss: 53.270training... 13800/100000: loss: 53.067training... 13900/100000: loss: 52.925training... 14000/100000: loss: 52.977training... 14100/100000: loss: 53.052training... 14200/100000: loss: 52.532training... 14300/100000: loss: 52.433training... 14400/100000: loss: 53.240training... 14500/100000: loss: 52.368training... 14600/100000: loss: 52.124training... 14700/100000: loss: 52.237training... 14800/100000: loss: 51.935training... 14900/100000: loss: 51.738training... 15000/100000: loss: 52.264training... 15100/100000: loss: 51.987training... 15200/100000: loss: 51.704training... 15300/100000: loss: 51.680training... 15400/100000: loss: 51.745training... 15500/100000: loss: 52.308training... 15600/100000: loss: 51.087training... 15700/100000: loss: 50.978training... 15800/100000: loss: 51.466training... 15900/100000: loss: 51.251training... 16000/100000: loss: 51.188training... 16100/100000: loss: 50.968training... 16200/100000: loss: 50.535training... 16300/100000: loss: 50.983training... 16400/100000: loss: 51.292training... 16500/100000: loss: 50.314training... 16600/100000: loss: 50.506training... 16700/100000: loss: 50.287training... 16800/100000: loss: 49.836training... 16900/100000: loss: 50.310training... 17000/100000: loss: 50.215training... 17100/100000: loss: 49.561training... 17200/100000: loss: 50.306training... 17300/100000: loss: 50.321training... 17400/100000: loss: 50.180training... 17500/100000: loss: 49.688training... 17600/100000: loss: 49.617training... 17700/100000: loss: 49.708training... 17800/100000: loss: 49.008training... 17900/100000: loss: 49.485training... 18000/100000: loss: 49.528training... 18100/100000: loss: 48.765training... 18200/100000: loss: 49.159training... 18300/100000: loss: 49.116training... 18400/100000: loss: 49.447training... 18500/100000: loss: 49.769training... 18600/100000: loss: 48.352training... 18700/100000: loss: 48.707training... 18800/100000: loss: 48.095training... 18900/100000: loss: 48.434training... 19000/100000: loss: 48.674training... 19100/100000: loss: 48.708training... 19200/100000: loss: 48.247training... 19300/100000: loss: 48.174training... 19400/100000: loss: 48.531training... 19500/100000: loss: 47.619training... 19600/100000: loss: 48.692training... 19700/100000: loss: 48.057training... 19800/100000: loss: 47.995training... 19900/100000: loss: 47.958training... 20000/100000: loss: 47.404training... 20100/100000: loss: 48.245training... 20200/100000: loss: 48.028training... 20300/100000: loss: 47.493training... 20400/100000: loss: 47.454training... 20500/100000: loss: 47.436training... 20600/100000: loss: 47.603training... 20700/100000: loss: 46.982training... 20800/100000: loss: 46.693training... 20900/100000: loss: 46.925training... 21000/100000: loss: 47.122training... 21100/100000: loss: 47.355training... 21200/100000: loss: 46.723training... 21300/100000: loss: 47.526training... 21400/100000: loss: 46.645training... 21500/100000: loss: 46.663training... 21600/100000: loss: 47.084training... 21700/100000: loss: 46.965training... 21800/100000: loss: 47.097training... 21900/100000: loss: 46.856training... 22000/100000: loss: 46.580training... 22100/100000: loss: 46.302training... 22200/100000: loss: 46.164training... 22300/100000: loss: 46.268training... 22400/100000: loss: 46.106training... 22500/100000: loss: 46.157training... 22600/100000: loss: 45.824training... 22700/100000: loss: 46.058training... 22800/100000: loss: 46.425training... 22900/100000: loss: 46.367training... 23000/100000: loss: 45.668training... 23100/100000: loss: 46.128training... 23200/100000: loss: 46.112training... 23300/100000: loss: 45.845training... 23400/100000: loss: 45.804training... 23500/100000: loss: 46.101training... 23600/100000: loss: 45.574training... 23700/100000: loss: 45.992training... 23800/100000: loss: 45.780training... 23900/100000: loss: 45.456training... 24000/100000: loss: 45.753training... 24100/100000: loss: 45.561training... 24200/100000: loss: 45.315training... 24300/100000: loss: 45.051training... 24400/100000: loss: 45.258training... 24500/100000: loss: 44.795training... 24600/100000: loss: 45.508training... 24700/100000: loss: 45.309training... 24800/100000: loss: 44.423training... 24900/100000: loss: 45.469training... 25000/100000: loss: 44.902training... 25100/100000: loss: 45.309training... 25200/100000: loss: 44.523training... 25300/100000: loss: 44.844training... 25400/100000: loss: 44.712training... 25500/100000: loss: 44.885training... 25600/100000: loss: 44.691training... 25700/100000: loss: 44.611training... 25800/100000: loss: 44.516training... 25900/100000: loss: 44.069training... 26000/100000: loss: 44.806training... 26100/100000: loss: 44.294training... 26200/100000: loss: 44.610training... 26300/100000: loss: 44.586training... 26400/100000: loss: 44.321training... 26500/100000: loss: 44.518training... 26600/100000: loss: 44.298training... 26700/100000: loss: 43.995training... 26800/100000: loss: 44.229training... 26900/100000: loss: 44.405training... 27000/100000: loss: 44.292training... 27100/100000: loss: 43.792training... 27200/100000: loss: 43.793training... 27300/100000: loss: 44.116training... 27400/100000: loss: 43.919training... 27500/100000: loss: 44.037training... 27600/100000: loss: 43.721training... 27700/100000: loss: 43.979training... 27800/100000: loss: 43.332training... 27900/100000: loss: 43.491training... 28000/100000: loss: 43.576training... 28100/100000: loss: 43.718training... 28200/100000: loss: 43.101training... 28300/100000: loss: 43.270training... 28400/100000: loss: 43.104training... 28500/100000: loss: 43.783training... 28600/100000: loss: 43.232training... 28700/100000: loss: 43.767training... 28800/100000: loss: 43.265training... 28900/100000: loss: 43.026training... 29000/100000: loss: 43.390training... 29100/100000: loss: 42.789training... 29200/100000: loss: 43.186training... 29300/100000: loss: 42.939training... 29400/100000: loss: 42.887training... 29500/100000: loss: 42.980training... 29600/100000: loss: 43.065training... 29700/100000: loss: 43.333training... 29800/100000: loss: 42.775training... 29900/100000: loss: 43.144training... 30000/100000: loss: 42.500training... 30100/100000: loss: 42.899training... 30200/100000: loss: 42.407training... 30300/100000: loss: 42.703training... 30400/100000: loss: 42.458training... 30500/100000: loss: 42.446training... 30600/100000: loss: 42.534training... 30700/100000: loss: 42.864training... 30800/100000: loss: 42.751training... 30900/100000: loss: 42.136training... 31000/100000: loss: 42.234training... 31100/100000: loss: 42.209training... 31200/100000: loss: 42.319training... 31300/100000: loss: 42.857training... 31400/100000: loss: 41.938training... 31500/100000: loss: 42.053training... 31600/100000: loss: 42.788training... 31700/100000: loss: 41.694training... 31800/100000: loss: 42.514training... 31900/100000: loss: 42.022training... 32000/100000: loss: 41.730training... 32100/100000: loss: 41.963training... 32200/100000: loss: 42.251training... 32300/100000: loss: 41.793training... 32400/100000: loss: 41.400training... 32500/100000: loss: 41.647training... 32600/100000: loss: 41.754training... 32700/100000: loss: 41.931training... 32800/100000: loss: 41.988training... 32900/100000: loss: 41.363training... 33000/100000: loss: 41.981training... 33100/100000: loss: 41.792training... 33200/100000: loss: 42.254training... 33300/100000: loss: 41.180training... 33400/100000: loss: 41.476training... 33500/100000: loss: 41.352training... 33600/100000: loss: 41.489training... 33700/100000: loss: 41.655training... 33800/100000: loss: 41.321training... 33900/100000: loss: 41.569training... 34000/100000: loss: 41.678training... 34100/100000: loss: 41.127training... 34200/100000: loss: 41.787training... 34300/100000: loss: 41.168training... 34400/100000: loss: 40.894training... 34500/100000: loss: 41.446training... 34600/100000: loss: 41.062training... 34700/100000: loss: 41.179training... 34800/100000: loss: 40.594training... 34900/100000: loss: 41.155training... 35000/100000: loss: 41.210training... 35100/100000: loss: 41.229training... 35200/100000: loss: 40.592training... 35300/100000: loss: 41.012training... 35400/100000: loss: 40.918training... 35500/100000: loss: 40.566training... 35600/100000: loss: 40.396training... 35700/100000: loss: 40.850training... 35800/100000: loss: 40.878training... 35900/100000: loss: 41.446training... 36000/100000: loss: 40.480training... 36100/100000: loss: 40.341training... 36200/100000: loss: 40.611training... 36300/100000: loss: 40.565training... 36400/100000: loss: 40.504training... 36500/100000: loss: 40.783training... 36600/100000: loss: 40.215training... 36700/100000: loss: 40.724training... 36800/100000: loss: 40.142training... 36900/100000: loss: 40.877training... 37000/100000: loss: 40.477training... 37100/100000: loss: 40.183training... 37200/100000: loss: 40.194training... 37300/100000: loss: 39.854training... 37400/100000: loss: 40.135training... 37500/100000: loss: 40.723training... 37600/100000: loss: 40.133training... 37700/100000: loss: 40.115training... 37800/100000: loss: 39.743training... 37900/100000: loss: 40.417training... 38000/100000: loss: 39.826training... 38100/100000: loss: 39.582training... 38200/100000: loss: 40.209training... 38300/100000: loss: 40.174training... 38400/100000: loss: 39.780training... 38500/100000: loss: 40.095training... 38600/100000: loss: 39.949training... 38700/100000: loss: 39.900training... 38800/100000: loss: 39.601training... 38900/100000: loss: 39.660training... 39000/100000: loss: 40.231training... 39100/100000: loss: 40.243training... 39200/100000: loss: 39.513training... 39300/100000: loss: 40.089training... 39400/100000: loss: 39.890training... 39500/100000: loss: 40.048training... 39600/100000: loss: 39.596training... 39700/100000: loss: 40.025training... 39800/100000: loss: 39.560training... 39900/100000: loss: 39.572training... 40000/100000: loss: 39.397training... 40100/100000: loss: 39.679training... 40200/100000: loss: 39.927training... 40300/100000: loss: 39.038training... 40400/100000: loss: 39.617training... 40500/100000: loss: 39.121training... 40600/100000: loss: 39.629training... 40700/100000: loss: 39.178training... 40800/100000: loss: 38.748training... 40900/100000: loss: 39.378training... 41000/100000: loss: 39.023training... 41100/100000: loss: 39.457training... 41200/100000: loss: 38.991training... 41300/100000: loss: 39.388training... 41400/100000: loss: 39.006training... 41500/100000: loss: 39.060training... 41600/100000: loss: 38.959training... 41700/100000: loss: 39.191training... 41800/100000: loss: 38.997training... 41900/100000: loss: 38.717training... 42000/100000: loss: 38.888training... 42100/100000: loss: 39.010training... 42200/100000: loss: 39.722training... 42300/100000: loss: 38.774training... 42400/100000: loss: 38.358training... 42500/100000: loss: 38.861training... 42600/100000: loss: 38.941training... 42700/100000: loss: 38.548training... 42800/100000: loss: 38.937training... 42900/100000: loss: 38.986training... 43000/100000: loss: 38.732training... 43100/100000: loss: 38.136training... 43200/100000: loss: 39.346training... 43300/100000: loss: 38.529training... 43400/100000: loss: 38.996training... 43500/100000: loss: 38.874training... 43600/100000: loss: 38.295training... 43700/100000: loss: 38.031training... 43800/100000: loss: 38.217training... 43900/100000: loss: 38.225training... 44000/100000: loss: 38.366training... 44100/100000: loss: 38.411training... 44200/100000: loss: 37.967training... 44300/100000: loss: 37.665training... 44400/100000: loss: 38.441training... 44500/100000: loss: 38.366training... 44600/100000: loss: 38.776training... 44700/100000: loss: 38.149training... 44800/100000: loss: 38.288training... 44900/100000: loss: 37.906training... 45000/100000: loss: 38.627training... 45100/100000: loss: 38.571training... 45200/100000: loss: 38.242training... 45300/100000: loss: 38.007training... 45400/100000: loss: 38.152training... 45500/100000: loss: 38.551training... 45600/100000: loss: 37.682training... 45700/100000: loss: 38.304training... 45800/100000: loss: 38.155training... 45900/100000: loss: 37.627training... 46000/100000: loss: 37.946training... 46100/100000: loss: 37.739training... 46200/100000: loss: 38.034training... 46300/100000: loss: 37.580training... 46400/100000: loss: 37.588training... 46500/100000: loss: 37.634training... 46600/100000: loss: 37.978training... 46700/100000: loss: 38.015training... 46800/100000: loss: 37.736training... 46900/100000: loss: 38.164training... 47000/100000: loss: 37.623training... 47100/100000: loss: 37.524training... 47200/100000: loss: 37.850training... 47300/100000: loss: 37.301training... 47400/100000: loss: 37.447training... 47500/100000: loss: 37.573training... 47600/100000: loss: 37.585training... 47700/100000: loss: 37.318training... 47800/100000: loss: 37.848training... 47900/100000: loss: 37.582training... 48000/100000: loss: 37.357training... 48100/100000: loss: 37.740training... 48200/100000: loss: 37.006training... 48300/100000: loss: 37.177training... 48400/100000: loss: 37.930training... 48500/100000: loss: 37.632training... 48600/100000: loss: 37.243training... 48700/100000: loss: 36.773training... 48800/100000: loss: 37.094training... 48900/100000: loss: 37.328training... 49000/100000: loss: 37.392training... 49100/100000: loss: 37.159training... 49200/100000: loss: 37.144training... 49300/100000: loss: 36.652training... 49400/100000: loss: 37.074training... 49500/100000: loss: 37.197training... 49600/100000: loss: 37.102training... 49700/100000: loss: 36.759training... 49800/100000: loss: 37.684training... 49900/100000: loss: 37.241training... 50000/100000: loss: 36.876training... 50100/100000: loss: 37.033training... 50200/100000: loss: 36.895training... 50300/100000: loss: 36.889training... 50400/100000: loss: 36.632training... 50500/100000: loss: 36.674training... 50600/100000: loss: 36.668training... 50700/100000: loss: 37.236training... 50800/100000: loss: 37.141training... 50900/100000: loss: 36.775training... 51000/100000: loss: 36.712training... 51100/100000: loss: 37.015training... 51200/100000: loss: 36.823training... 51300/100000: loss: 36.717training... 51400/100000: loss: 36.563training... 51500/100000: loss: 36.320training... 51600/100000: loss: 36.505training... 51700/100000: loss: 36.894training... 51800/100000: loss: 36.593training... 51900/100000: loss: 36.521training... 52000/100000: loss: 36.136training... 52100/100000: loss: 36.477training... 52200/100000: loss: 36.570training... 52300/100000: loss: 36.581training... 52400/100000: loss: 36.975training... 52500/100000: loss: 36.759training... 52600/100000: loss: 36.544training... 52700/100000: loss: 35.961training... 52800/100000: loss: 36.485training... 52900/100000: loss: 36.127training... 53000/100000: loss: 36.240training... 53100/100000: loss: 36.413training... 53200/100000: loss: 36.037training... 53300/100000: loss: 35.946training... 53400/100000: loss: 35.988training... 53500/100000: loss: 36.511training... 53600/100000: loss: 35.958training... 53700/100000: loss: 35.897training... 53800/100000: loss: 36.099training... 53900/100000: loss: 36.514training... 54000/100000: loss: 36.567training... 54100/100000: loss: 35.860training... 54200/100000: loss: 35.837training... 54300/100000: loss: 35.953training... 54400/100000: loss: 36.116training... 54500/100000: loss: 36.437training... 54600/100000: loss: 36.115training... 54700/100000: loss: 35.637training... 54800/100000: loss: 35.962training... 54900/100000: loss: 36.060training... 55000/100000: loss: 36.447training... 55100/100000: loss: 36.189training... 55200/100000: loss: 35.895training... 55300/100000: loss: 35.808training... 55400/100000: loss: 36.061training... 55500/100000: loss: 35.788training... 55600/100000: loss: 36.112training... 55700/100000: loss: 35.911training... 55800/100000: loss: 36.146training... 55900/100000: loss: 35.704training... 56000/100000: loss: 35.318training... 56100/100000: loss: 35.347training... 56200/100000: loss: 35.896training... 56300/100000: loss: 35.521training... 56400/100000: loss: 36.107training... 56500/100000: loss: 35.734training... 56600/100000: loss: 35.849training... 56700/100000: loss: 35.554training... 56800/100000: loss: 35.214training... 56900/100000: loss: 35.696training... 57000/100000: loss: 35.225training... 57100/100000: loss: 35.406training... 57200/100000: loss: 35.186training... 57300/100000: loss: 35.833training... 57400/100000: loss: 35.536training... 57500/100000: loss: 35.783training... 57600/100000: loss: 35.577training... 57700/100000: loss: 35.589training... 57800/100000: loss: 35.695training... 57900/100000: loss: 35.474training... 58000/100000: loss: 35.372training... 58100/100000: loss: 34.995training... 58200/100000: loss: 35.650training... 58300/100000: loss: 35.198training... 58400/100000: loss: 35.212training... 58500/100000: loss: 35.314training... 58600/100000: loss: 35.076training... 58700/100000: loss: 35.115training... 58800/100000: loss: 35.571training... 58900/100000: loss: 35.195training... 59000/100000: loss: 35.096training... 59100/100000: loss: 34.627training... 59200/100000: loss: 35.438training... 59300/100000: loss: 34.998training... 59400/100000: loss: 35.483training... 59500/100000: loss: 34.956training... 59600/100000: loss: 34.929training... 59700/100000: loss: 34.882training... 59800/100000: loss: 34.968training... 59900/100000: loss: 35.046training... 60000/100000: loss: 34.803training... 60100/100000: loss: 35.137training... 60200/100000: loss: 34.770training... 60300/100000: loss: 34.814training... 60400/100000: loss: 34.821training... 60500/100000: loss: 34.778training... 60600/100000: loss: 35.376training... 60700/100000: loss: 34.996training... 60800/100000: loss: 34.948training... 60900/100000: loss: 34.997training... 61000/100000: loss: 34.864training... 61100/100000: loss: 34.677training... 61200/100000: loss: 34.573training... 61300/100000: loss: 34.918training... 61400/100000: loss: 34.836training... 61500/100000: loss: 34.454training... 61600/100000: loss: 34.787training... 61700/100000: loss: 34.278training... 61800/100000: loss: 34.808training... 61900/100000: loss: 34.699training... 62000/100000: loss: 34.644training... 62100/100000: loss: 34.672training... 62200/100000: loss: 34.928training... 62300/100000: loss: 34.616training... 62400/100000: loss: 34.554training... 62500/100000: loss: 34.402training... 62600/100000: loss: 34.272training... 62700/100000: loss: 34.818training... 62800/100000: loss: 34.841training... 62900/100000: loss: 34.735training... 63000/100000: loss: 34.514training... 63100/100000: loss: 34.247training... 63200/100000: loss: 34.441training... 63300/100000: loss: 34.490training... 63400/100000: loss: 34.436training... 63500/100000: loss: 34.644training... 63600/100000: loss: 34.074training... 63700/100000: loss: 34.733training... 63800/100000: loss: 34.714training... 63900/100000: loss: 34.402training... 64000/100000: loss: 34.011training... 64100/100000: loss: 34.644training... 64200/100000: loss: 34.273training... 64300/100000: loss: 34.384training... 64400/100000: loss: 34.019training... 64500/100000: loss: 34.346training... 64600/100000: loss: 34.406training... 64700/100000: loss: 34.150training... 64800/100000: loss: 33.704training... 64900/100000: loss: 33.998training... 65000/100000: loss: 34.460training... 65100/100000: loss: 34.141training... 65200/100000: loss: 34.376training... 65300/100000: loss: 33.502training... 65400/100000: loss: 33.951training... 65500/100000: loss: 34.163training... 65600/100000: loss: 34.021training... 65700/100000: loss: 34.268training... 65800/100000: loss: 33.947training... 65900/100000: loss: 34.063training... 66000/100000: loss: 33.800training... 66100/100000: loss: 34.129training... 66200/100000: loss: 33.867training... 66300/100000: loss: 34.128training... 66400/100000: loss: 33.702training... 66500/100000: loss: 33.950training... 66600/100000: loss: 33.579training... 66700/100000: loss: 33.680training... 66800/100000: loss: 33.440training... 66900/100000: loss: 33.784training... 67000/100000: loss: 33.867training... 67100/100000: loss: 33.737training... 67200/100000: loss: 33.909training... 67300/100000: loss: 33.896training... 67400/100000: loss: 33.721training... 67500/100000: loss: 33.550training... 67600/100000: loss: 33.768training... 67700/100000: loss: 33.495training... 67800/100000: loss: 33.532training... 67900/100000: loss: 33.554training... 68000/100000: loss: 33.799training... 68100/100000: loss: 33.761training... 68200/100000: loss: 33.796training... 68300/100000: loss: 33.540training... 68400/100000: loss: 33.984training... 68500/100000: loss: 33.620training... 68600/100000: loss: 33.773training... 68700/100000: loss: 33.421training... 68800/100000: loss: 33.425training... 68900/100000: loss: 32.997training... 69000/100000: loss: 33.384training... 69100/100000: loss: 33.531training... 69200/100000: loss: 33.414training... 69300/100000: loss: 33.735training... 69400/100000: loss: 33.681training... 69500/100000: loss: 33.224training... 69600/100000: loss: 33.604training... 69700/100000: loss: 33.354training... 69800/100000: loss: 33.099training... 69900/100000: loss: 33.356training... 70000/100000: loss: 33.402training... 70100/100000: loss: 33.394training... 70200/100000: loss: 33.322training... 70300/100000: loss: 33.137training... 70400/100000: loss: 33.300training... 70500/100000: loss: 33.202training... 70600/100000: loss: 33.103training... 70700/100000: loss: 33.435training... 70800/100000: loss: 33.136training... 70900/100000: loss: 33.361training... 71000/100000: loss: 33.043training... 71100/100000: loss: 32.869training... 71200/100000: loss: 32.662training... 71300/100000: loss: 33.722training... 71400/100000: loss: 32.917training... 71500/100000: loss: 32.972training... 71600/100000: loss: 32.654training... 71700/100000: loss: 32.926training... 71800/100000: loss: 32.888training... 71900/100000: loss: 32.785training... 72000/100000: loss: 33.141training... 72100/100000: loss: 32.617training... 72200/100000: loss: 32.931training... 72300/100000: loss: 33.262training... 72400/100000: loss: 33.021training... 72500/100000: loss: 32.720training... 72600/100000: loss: 32.767training... 72700/100000: loss: 32.759training... 72800/100000: loss: 32.858training... 72900/100000: loss: 32.617training... 73000/100000: loss: 33.409training... 73100/100000: loss: 33.253training... 73200/100000: loss: 32.512training... 73300/100000: loss: 32.532training... 73400/100000: loss: 32.640training... 73500/100000: loss: 32.653training... 73600/100000: loss: 32.499training... 73700/100000: loss: 32.552training... 73800/100000: loss: 32.592training... 73900/100000: loss: 32.654training... 74000/100000: loss: 32.852training... 74100/100000: loss: 32.668training... 74200/100000: loss: 32.867training... 74300/100000: loss: 32.271training... 74400/100000: loss: 32.411training... 74500/100000: loss: 32.580training... 74600/100000: loss: 32.578training... 74700/100000: loss: 32.805training... 74800/100000: loss: 32.539training... 74900/100000: loss: 32.262training... 75000/100000: loss: 32.584training... 75100/100000: loss: 32.605training... 75200/100000: loss: 32.635training... 75300/100000: loss: 32.350training... 75400/100000: loss: 32.698training... 75500/100000: loss: 32.199training... 75600/100000: loss: 32.314training... 75700/100000: loss: 32.973training... 75800/100000: loss: 32.554training... 75900/100000: loss: 32.278training... 76000/100000: loss: 32.290training... 76100/100000: loss: 32.167training... 76200/100000: loss: 32.012training... 76300/100000: loss: 32.112training... 76400/100000: loss: 32.089training... 76500/100000: loss: 32.605training... 76600/100000: loss: 32.374training... 76700/100000: loss: 32.488training... 76800/100000: loss: 32.307training... 76900/100000: loss: 32.482training... 77000/100000: loss: 32.462training... 77100/100000: loss: 31.919training... 77200/100000: loss: 32.119training... 77300/100000: loss: 32.099training... 77400/100000: loss: 32.377training... 77500/100000: loss: 32.168training... 77600/100000: loss: 32.565training... 77700/100000: loss: 32.356training... 77800/100000: loss: 32.275training... 77900/100000: loss: 32.044training... 78000/100000: loss: 32.026training... 78100/100000: loss: 32.142training... 78200/100000: loss: 32.294training... 78300/100000: loss: 31.639training... 78400/100000: loss: 32.247training... 78500/100000: loss: 32.456training... 78600/100000: loss: 32.076training... 78700/100000: loss: 31.940training... 78800/100000: loss: 32.048training... 78900/100000: loss: 31.898training... 79000/100000: loss: 32.032training... 79100/100000: loss: 32.002training... 79200/100000: loss: 31.788training... 79300/100000: loss: 32.097training... 79400/100000: loss: 31.814training... 79500/100000: loss: 31.988training... 79600/100000: loss: 32.148training... 79700/100000: loss: 31.792training... 79800/100000: loss: 32.262training... 79900/100000: loss: 31.928training... 80000/100000: loss: 31.959training... 80100/100000: loss: 32.043training... 80200/100000: loss: 31.884training... 80300/100000: loss: 31.538training... 80400/100000: loss: 31.892training... 80500/100000: loss: 31.879training... 80600/100000: loss: 31.622training... 80700/100000: loss: 31.911training... 80800/100000: loss: 31.946training... 80900/100000: loss: 31.802training... 81000/100000: loss: 32.086training... 81100/100000: loss: 31.726training... 81200/100000: loss: 31.639training... 81300/100000: loss: 32.180training... 81400/100000: loss: 31.329training... 81500/100000: loss: 31.399training... 81600/100000: loss: 31.611training... 81700/100000: loss: 31.973training... 81800/100000: loss: 31.702training... 81900/100000: loss: 31.522training... 82000/100000: loss: 31.736training... 82100/100000: loss: 32.238training... 82200/100000: loss: 31.489training... 82300/100000: loss: 31.695training... 82400/100000: loss: 31.778training... 82500/100000: loss: 31.923training... 82600/100000: loss: 31.997training... 82700/100000: loss: 31.672training... 82800/100000: loss: 31.205training... 82900/100000: loss: 31.357training... 83000/100000: loss: 31.460training... 83100/100000: loss: 31.481training... 83200/100000: loss: 31.608training... 83300/100000: loss: 31.499training... 83400/100000: loss: 31.798training... 83500/100000: loss: 31.661training... 83600/100000: loss: 31.381training... 83700/100000: loss: 31.076training... 83800/100000: loss: 31.310training... 83900/100000: loss: 31.433training... 84000/100000: loss: 31.791training... 84100/100000: loss: 31.803training... 84200/100000: loss: 31.414training... 84300/100000: loss: 31.505training... 84400/100000: loss: 31.248training... 84500/100000: loss: 31.335training... 84600/100000: loss: 31.467training... 84700/100000: loss: 31.629training... 84800/100000: loss: 31.161training... 84900/100000: loss: 31.467training... 85000/100000: loss: 30.998training... 85100/100000: loss: 31.575training... 85200/100000: loss: 31.227training... 85300/100000: loss: 31.232training... 85400/100000: loss: 31.324training... 85500/100000: loss: 30.963training... 85600/100000: loss: 31.535training... 85700/100000: loss: 31.370training... 85800/100000: loss: 31.458training... 85900/100000: loss: 31.027training... 86000/100000: loss: 31.354training... 86100/100000: loss: 31.090training... 86200/100000: loss: 31.362training... 86300/100000: loss: 31.191training... 86400/100000: loss: 31.064training... 86500/100000: loss: 31.054training... 86600/100000: loss: 31.347training... 86700/100000: loss: 31.070training... 86800/100000: loss: 31.558training... 86900/100000: loss: 31.082training... 87000/100000: loss: 31.089training... 87100/100000: loss: 31.160training... 87200/100000: loss: 30.997training... 87300/100000: loss: 31.103training... 87400/100000: loss: 31.195training... 87500/100000: loss: 31.008training... 87600/100000: loss: 31.032training... 87700/100000: loss: 31.250training... 87800/100000: loss: 31.458training... 87900/100000: loss: 31.107training... 88000/100000: loss: 30.946training... 88100/100000: loss: 31.104training... 88200/100000: loss: 31.193training... 88300/100000: loss: 31.403training... 88400/100000: loss: 31.063training... 88500/100000: loss: 31.007training... 88600/100000: loss: 31.075training... 88700/100000: loss: 31.271training... 88800/100000: loss: 31.050training... 88900/100000: loss: 31.252training... 89000/100000: loss: 30.872training... 89100/100000: loss: 30.855training... 89200/100000: loss: 31.218training... 89300/100000: loss: 30.852training... 89400/100000: loss: 30.923training... 89500/100000: loss: 30.949training... 89600/100000: loss: 30.862training... 89700/100000: loss: 31.005training... 89800/100000: loss: 31.181training... 89900/100000: loss: 30.819training... 90000/100000: loss: 31.322training... 90100/100000: loss: 31.107training... 90200/100000: loss: 30.983training... 90300/100000: loss: 30.622training... 90400/100000: loss: 30.821training... 90500/100000: loss: 30.879training... 90600/100000: loss: 30.416training... 90700/100000: loss: 30.653training... 90800/100000: loss: 30.760training... 90900/100000: loss: 30.525training... 91000/100000: loss: 31.034training... 91100/100000: loss: 30.836training... 91200/100000: loss: 30.599training... 91300/100000: loss: 31.024training... 91400/100000: loss: 30.693training... 91500/100000: loss: 30.522training... 91600/100000: loss: 30.412training... 91700/100000: loss: 30.683training... 91800/100000: loss: 30.314training... 91900/100000: loss: 30.704training... 92000/100000: loss: 30.518training... 92100/100000: loss: 30.660training... 92200/100000: loss: 30.422training... 92300/100000: loss: 30.620training... 92400/100000: loss: 30.939training... 92500/100000: loss: 30.871training... 92600/100000: loss: 30.738training... 92700/100000: loss: 30.556training... 92800/100000: loss: 31.017training... 92900/100000: loss: 30.526training... 93000/100000: loss: 30.493training... 93100/100000: loss: 30.670training... 93200/100000: loss: 30.424training... 93300/100000: loss: 30.472training... 93400/100000: loss: 30.658training... 93500/100000: loss: 30.634training... 93600/100000: loss: 30.721training... 93700/100000: loss: 30.404training... 93800/100000: loss: 30.692training... 93900/100000: loss: 30.753training... 94000/100000: loss: 30.284training... 94100/100000: loss: 30.555training... 94200/100000: loss: 30.617training... 94300/100000: loss: 30.513training... 94400/100000: loss: 30.527training... 94500/100000: loss: 30.486training... 94600/100000: loss: 30.628training... 94700/100000: loss: 30.281training... 94800/100000: loss: 30.119training... 94900/100000: loss: 30.581training... 95000/100000: loss: 30.478training... 95100/100000: loss: 30.307training... 95200/100000: loss: 30.292training... 95300/100000: loss: 30.286training... 95400/100000: loss: 30.430training... 95500/100000: loss: 30.619training... 95600/100000: loss: 30.419training... 95700/100000: loss: 30.623training... 95800/100000: loss: 29.984training... 95900/100000: loss: 30.193training... 96000/100000: loss: 30.713training... 96100/100000: loss: 30.566training... 96200/100000: loss: 30.382training... 96300/100000: loss: 30.550training... 96400/100000: loss: 30.055training... 96500/100000: loss: 30.361training... 96600/100000: loss: 30.277training... 96700/100000: loss: 29.881training... 96800/100000: loss: 30.301training... 96900/100000: loss: 30.304training... 97000/100000: loss: 30.252training... 97100/100000: loss: 30.280training... 97200/100000: loss: 30.017training... 97300/100000: loss: 30.297training... 97400/100000: loss: 30.538training... 97500/100000: loss: 30.172training... 97600/100000: loss: 30.216training... 97700/100000: loss: 30.353training... 97800/100000: loss: 30.154training... 97900/100000: loss: 30.112training... 98000/100000: loss: 29.974training... 98100/100000: loss: 30.190training... 98200/100000: loss: 30.347training... 98300/100000: loss: 30.196training... 98400/100000: loss: 30.322training... 98500/100000: loss: 30.147training... 98600/100000: loss: 30.167training... 98700/100000: loss: 30.320training... 98800/100000: loss: 30.432training... 98900/100000: loss: 30.269training... 99000/100000: loss: 30.012training... 99100/100000: loss: 29.847training... 99200/100000: loss: 30.328training... 99300/100000: loss: 30.374training... 99400/100000: loss: 30.217training... 99500/100000: loss: 29.869training... 99600/100000: loss: 30.018training... 99700/100000: loss: 30.327training... 99800/100000: loss: 30.199training... 99900/100000: loss: 30.096training... 100000/100000: loss: 30.333
>>> It elapsed 4458.06 seconds for training
>>> Star initialized.
>>> Draping...
>>> It takes 7.605 ms for draping
>>> OBJ file [./example/pose_0_10.obj] save completed.
>>> Draping...
>>> It takes 5.907 ms for draping
>>> OBJ file [./example/pose_1_10.obj] save completed.
>>> Draping...
>>> It takes 8.879 ms for draping
>>> OBJ file [./example/pose_2_10.obj] save completed.
>>> Draping...
>>> It takes 38.318 ms for draping
>>> OBJ file [./example/pose_3_10.obj] save completed.
>>> Draping...
>>> It takes 6.467 ms for draping
>>> OBJ file [./example/pose_4_10.obj] save completed.
>>> Draping...
>>> It takes 10.565 ms for draping
>>> OBJ file [./example/pose_5_10.obj] save completed.
>>> Draping...
>>> It takes 49.458 ms for draping
>>> OBJ file [./example/pose_6_10.obj] save completed.
>>> Draping...
>>> It takes 5.891 ms for draping
>>> OBJ file [./example/pose_7_10.obj] save completed.
>>> Draping...
>>> It takes 7.913 ms for draping
>>> OBJ file [./example/pose_8_10.obj] save completed.
>>> Draping...
>>> It takes 5.878 ms for draping
>>> OBJ file [./example/pose_9_10.obj] save completed.
>>> Draping...
>>> It takes 46.421 ms for draping
>>> OBJ file [./example/pose_10_10.obj] save completed.
