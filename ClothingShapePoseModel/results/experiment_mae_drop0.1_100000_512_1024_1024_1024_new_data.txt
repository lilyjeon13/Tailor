>>> Initializing clothing shape model...
>>> Star initialized.
>>> Get parameters list...
>>> Length of pose: 231
>>> Length of shape: 1
>>> Length of data: 231
self.base_body_list is 
['../../Data/base_body/pose_0153/subject_0000_params.json', '../../Data/base_body/pose_0079/subject_0000_params.json', '../../Data/base_body/pose_0133/subject_0000_params.json', '../../Data/base_body/pose_0206/subject_0000_params.json', '../../Data/base_body/pose_0023/subject_0000_params.json', '../../Data/base_body/pose_0144/subject_0000_params.json', '../../Data/base_body/pose_0202/subject_0000_params.json', '../../Data/base_body/pose_0191/subject_0000_params.json', '../../Data/base_body/pose_0222/subject_0000_params.json', '../../Data/base_body/pose_0041/subject_0000_params.json', '../../Data/base_body/pose_0109/subject_0000_params.json', '../../Data/base_body/pose_0168/subject_0000_params.json', '../../Data/base_body/pose_0224/subject_0000_params.json', '../../Data/base_body/pose_0215/subject_0000_params.json', '../../Data/base_body/pose_0143/subject_0000_params.json', '../../Data/base_body/pose_0227/subject_0000_params.json', '../../Data/base_body/pose_0062/subject_0000_params.json', '../../Data/base_body/pose_0016/subject_0000_params.json', '../../Data/base_body/pose_0054/subject_0000_params.json', '../../Data/base_body/pose_0204/subject_0000_params.json', '../../Data/base_body/pose_0162/subject_0000_params.json', '../../Data/base_body/pose_0130/subject_0000_params.json', '../../Data/base_body/pose_0134/subject_0000_params.json', '../../Data/base_body/pose_0066/subject_0000_params.json', '../../Data/base_body/pose_0212/subject_0000_params.json', '../../Data/base_body/pose_0157/subject_0000_params.json', '../../Data/base_body/pose_0028/subject_0000_params.json', '../../Data/base_body/pose_0189/subject_0000_params.json', '../../Data/base_body/pose_0029/subject_0000_params.json', '../../Data/base_body/pose_0000/subject_0000_params.json', '../../Data/base_body/pose_0158/subject_0000_params.json', '../../Data/base_body/pose_0177/subject_0000_params.json', '../../Data/base_body/pose_0164/subject_0000_params.json', '../../Data/base_body/pose_0119/subject_0000_params.json', '../../Data/base_body/pose_0190/subject_0000_params.json', '../../Data/base_body/pose_0076/subject_0000_params.json', '../../Data/base_body/pose_0086/subject_0000_params.json', '../../Data/base_body/pose_0207/subject_0000_params.json', '../../Data/base_body/pose_0040/subject_0000_params.json', '../../Data/base_body/pose_0084/subject_0000_params.json', '../../Data/base_body/pose_0220/subject_0000_params.json', '../../Data/base_body/pose_0159/subject_0000_params.json', '../../Data/base_body/pose_0179/subject_0000_params.json', '../../Data/base_body/pose_0030/subject_0000_params.json', '../../Data/base_body/pose_0007/subject_0000_params.json', '../../Data/base_body/pose_0200/subject_0000_params.json', '../../Data/base_body/pose_0141/subject_0000_params.json', '../../Data/base_body/pose_0138/subject_0000_params.json', '../../Data/base_body/pose_0203/subject_0000_params.json', '../../Data/base_body/pose_0176/subject_0000_params.json', '../../Data/base_body/pose_0165/subject_0000_params.json', '../../Data/base_body/pose_0052/subject_0000_params.json', '../../Data/base_body/pose_0090/subject_0000_params.json', '../../Data/base_body/pose_0001/subject_0000_params.json', '../../Data/base_body/pose_0063/subject_0000_params.json', '../../Data/base_body/pose_0122/subject_0000_params.json', '../../Data/base_body/pose_0194/subject_0000_params.json', '../../Data/base_body/pose_0132/subject_0000_params.json', '../../Data/base_body/pose_0099/subject_0000_params.json', '../../Data/base_body/pose_0147/subject_0000_params.json', '../../Data/base_body/pose_0142/subject_0000_params.json', '../../Data/base_body/pose_0014/subject_0000_params.json', '../../Data/base_body/pose_0137/subject_0000_params.json', '../../Data/base_body/pose_0107/subject_0000_params.json', '../../Data/base_body/pose_0201/subject_0000_params.json', '../../Data/base_body/pose_0195/subject_0000_params.json', '../../Data/base_body/pose_0015/subject_0000_params.json', '../../Data/base_body/pose_0002/subject_0000_params.json', '../../Data/base_body/pose_0020/subject_0000_params.json', '../../Data/base_body/pose_0003/subject_0000_params.json', '../../Data/base_body/pose_0211/subject_0000_params.json', '../../Data/base_body/pose_0102/subject_0000_params.json', '../../Data/base_body/pose_0231/subject_0000_params.json', '../../Data/base_body/pose_0019/subject_0000_params.json', '../../Data/base_body/pose_0217/subject_0000_params.json', '../../Data/base_body/pose_0175/subject_0000_params.json', '../../Data/base_body/pose_0181/subject_0000_params.json', '../../Data/base_body/pose_0043/subject_0000_params.json', '../../Data/base_body/pose_0106/subject_0000_params.json', '../../Data/base_body/pose_0139/subject_0000_params.json', '../../Data/base_body/pose_0101/subject_0000_params.json', '../../Data/base_body/pose_0128/subject_0000_params.json', '../../Data/base_body/pose_0053/subject_0000_params.json', '../../Data/base_body/pose_0115/subject_0000_params.json', '../../Data/base_body/pose_0193/subject_0000_params.json', '../../Data/base_body/pose_0111/subject_0000_params.json', '../../Data/base_body/pose_0123/subject_0000_params.json', '../../Data/base_body/pose_0117/subject_0000_params.json', '../../Data/base_body/pose_0089/subject_0000_params.json', '../../Data/base_body/pose_0182/subject_0000_params.json', '../../Data/base_body/pose_0108/subject_0000_params.json', '../../Data/base_body/pose_0073/subject_0000_params.json', '../../Data/base_body/pose_0056/subject_0000_params.json', '../../Data/base_body/pose_0226/subject_0000_params.json', '../../Data/base_body/pose_0037/subject_0000_params.json', '../../Data/base_body/pose_0218/subject_0000_params.json', '../../Data/base_body/pose_0088/subject_0000_params.json', '../../Data/base_body/pose_0009/subject_0000_params.json', '../../Data/base_body/pose_0196/subject_0000_params.json', '../../Data/base_body/pose_0083/subject_0000_params.json', '../../Data/base_body/pose_0100/subject_0000_params.json', '../../Data/base_body/pose_0039/subject_0000_params.json', '../../Data/base_body/pose_0032/subject_0000_params.json', '../../Data/base_body/pose_0024/subject_0000_params.json', '../../Data/base_body/pose_0209/subject_0000_params.json', '../../Data/base_body/pose_0171/subject_0000_params.json', '../../Data/base_body/pose_0044/subject_0000_params.json', '../../Data/base_body/pose_0184/subject_0000_params.json', '../../Data/base_body/pose_0098/subject_0000_params.json', '../../Data/base_body/pose_0091/subject_0000_params.json', '../../Data/base_body/pose_0049/subject_0000_params.json', '../../Data/base_body/pose_0047/subject_0000_params.json', '../../Data/base_body/pose_0048/subject_0000_params.json', '../../Data/base_body/pose_0036/subject_0000_params.json', '../../Data/base_body/pose_0081/subject_0000_params.json', '../../Data/base_body/pose_0183/subject_0000_params.json', '../../Data/base_body/pose_0146/subject_0000_params.json', '../../Data/base_body/pose_0077/subject_0000_params.json', '../../Data/base_body/pose_0124/subject_0000_params.json', '../../Data/base_body/pose_0150/subject_0000_params.json', '../../Data/base_body/pose_0125/subject_0000_params.json', '../../Data/base_body/pose_0092/subject_0000_params.json', '../../Data/base_body/pose_0093/subject_0000_params.json', '../../Data/base_body/pose_0121/subject_0000_params.json', '../../Data/base_body/pose_0033/subject_0000_params.json', '../../Data/base_body/pose_0027/subject_0000_params.json', '../../Data/base_body/pose_0149/subject_0000_params.json', '../../Data/base_body/pose_0061/subject_0000_params.json', '../../Data/base_body/pose_0205/subject_0000_params.json', '../../Data/base_body/pose_0155/subject_0000_params.json', '../../Data/base_body/pose_0095/subject_0000_params.json', '../../Data/base_body/pose_0116/subject_0000_params.json', '../../Data/base_body/pose_0004/subject_0000_params.json', '../../Data/base_body/pose_0145/subject_0000_params.json', '../../Data/base_body/pose_0192/subject_0000_params.json', '../../Data/base_body/pose_0174/subject_0000_params.json', '../../Data/base_body/pose_0064/subject_0000_params.json', '../../Data/base_body/pose_0018/subject_0000_params.json', '../../Data/base_body/pose_0186/subject_0000_params.json', '../../Data/base_body/pose_0229/subject_0000_params.json', '../../Data/base_body/pose_0110/subject_0000_params.json', '../../Data/base_body/pose_0120/subject_0000_params.json', '../../Data/base_body/pose_0017/subject_0000_params.json', '../../Data/base_body/pose_0148/subject_0000_params.json', '../../Data/base_body/pose_0008/subject_0000_params.json', '../../Data/base_body/pose_0225/subject_0000_params.json', '../../Data/base_body/pose_0057/subject_0000_params.json', '../../Data/base_body/pose_0058/subject_0000_params.json', '../../Data/base_body/pose_0067/subject_0000_params.json', '../../Data/base_body/pose_0131/subject_0000_params.json', '../../Data/base_body/pose_0012/subject_0000_params.json', '../../Data/base_body/pose_0161/subject_0000_params.json', '../../Data/base_body/pose_0087/subject_0000_params.json', '../../Data/base_body/pose_0129/subject_0000_params.json', '../../Data/base_body/pose_0223/subject_0000_params.json', '../../Data/base_body/pose_0210/subject_0000_params.json', '../../Data/base_body/pose_0096/subject_0000_params.json', '../../Data/base_body/pose_0060/subject_0000_params.json', '../../Data/base_body/pose_0082/subject_0000_params.json', '../../Data/base_body/pose_0104/subject_0000_params.json', '../../Data/base_body/pose_0185/subject_0000_params.json', '../../Data/base_body/pose_0180/subject_0000_params.json', '../../Data/base_body/pose_0127/subject_0000_params.json', '../../Data/base_body/pose_0188/subject_0000_params.json', '../../Data/base_body/pose_0050/subject_0000_params.json', '../../Data/base_body/pose_0046/subject_0000_params.json', '../../Data/base_body/pose_0187/subject_0000_params.json', '../../Data/base_body/pose_0065/subject_0000_params.json', '../../Data/base_body/pose_0197/subject_0000_params.json', '../../Data/base_body/pose_0071/subject_0000_params.json', '../../Data/base_body/pose_0011/subject_0000_params.json', '../../Data/base_body/pose_0069/subject_0000_params.json', '../../Data/base_body/pose_0072/subject_0000_params.json', '../../Data/base_body/pose_0213/subject_0000_params.json', '../../Data/base_body/pose_0094/subject_0000_params.json', '../../Data/base_body/pose_0156/subject_0000_params.json', '../../Data/base_body/pose_0230/subject_0000_params.json', '../../Data/base_body/pose_0034/subject_0000_params.json', '../../Data/base_body/pose_0022/subject_0000_params.json', '../../Data/base_body/pose_0103/subject_0000_params.json', '../../Data/base_body/pose_0005/subject_0000_params.json', '../../Data/base_body/pose_0167/subject_0000_params.json', '../../Data/base_body/pose_0232/subject_0000_params.json', '../../Data/base_body/pose_0170/subject_0000_params.json', '../../Data/base_body/pose_0068/subject_0000_params.json', '../../Data/base_body/pose_0214/subject_0000_params.json', '../../Data/base_body/pose_0055/subject_0000_params.json', '../../Data/base_body/pose_0075/subject_0000_params.json', '../../Data/base_body/pose_0140/subject_0000_params.json', '../../Data/base_body/pose_0045/subject_0000_params.json', '../../Data/base_body/pose_0221/subject_0000_params.json', '../../Data/base_body/pose_0013/subject_0000_params.json', '../../Data/base_body/pose_0154/subject_0000_params.json', '../../Data/base_body/pose_0114/subject_0000_params.json', '../../Data/base_body/pose_0070/subject_0000_params.json', '../../Data/base_body/pose_0198/subject_0000_params.json', '../../Data/base_body/pose_0216/subject_0000_params.json', '../../Data/base_body/pose_0097/subject_0000_params.json', '../../Data/base_body/pose_0126/subject_0000_params.json', '../../Data/base_body/pose_0152/subject_0000_params.json', '../../Data/base_body/pose_0112/subject_0000_params.json', '../../Data/base_body/pose_0078/subject_0000_params.json', '../../Data/base_body/pose_0025/subject_0000_params.json', '../../Data/base_body/pose_0151/subject_0000_params.json', '../../Data/base_body/pose_0026/subject_0000_params.json', '../../Data/base_body/pose_0080/subject_0000_params.json', '../../Data/base_body/pose_0105/subject_0000_params.json', '../../Data/base_body/pose_0035/subject_0000_params.json', '../../Data/base_body/pose_0118/subject_0000_params.json', '../../Data/base_body/pose_0136/subject_0000_params.json', '../../Data/base_body/pose_0208/subject_0000_params.json', '../../Data/base_body/pose_0085/subject_0000_params.json', '../../Data/base_body/pose_0006/subject_0000_params.json', '../../Data/base_body/pose_0173/subject_0000_params.json', '../../Data/base_body/pose_0166/subject_0000_params.json', '../../Data/base_body/pose_0113/subject_0000_params.json', '../../Data/base_body/pose_0163/subject_0000_params.json', '../../Data/base_body/pose_0059/subject_0000_params.json', '../../Data/base_body/pose_0051/subject_0000_params.json', '../../Data/base_body/pose_0135/subject_0000_params.json', '../../Data/base_body/pose_0228/subject_0000_params.json', '../../Data/base_body/pose_0038/subject_0000_params.json', '../../Data/base_body/pose_0199/subject_0000_params.json', '../../Data/base_body/pose_0169/subject_0000_params.json', '../../Data/base_body/pose_0160/subject_0000_params.json', '../../Data/base_body/pose_0021/subject_0000_params.json', '../../Data/base_body/pose_0178/subject_0000_params.json', '../../Data/base_body/pose_0042/subject_0000_params.json', '../../Data/base_body/pose_0074/subject_0000_params.json', '../../Data/base_body/pose_0172/subject_0000_params.json', '../../Data/base_body/pose_0031/subject_0000_params.json']
../../Data/base_body/pose_0153/subject_0000/clothWhite2/subject_0000_clothWhite2-scale10.obj

>>> 100/231 loading...
>>> 200/231 loading...
>>> MLP dimensions: [20752, 512, 1024, 1024, 1024, 5283].
>>> training MLP starts

training... 0100/100000: loss: 2164.562
training... 0200/100000: loss: 1699.907
training... 0300/100000: loss: 1604.528
training... 0400/100000: loss: 1566.387
training... 0500/100000: loss: 1490.113
training... 0600/100000: loss: 1452.591
training... 0700/100000: loss: 1420.432
training... 0800/100000: loss: 1398.434
training... 0900/100000: loss: 1405.237
training... 1000/100000: loss: 1350.336
training... 1100/100000: loss: 1312.557
training... 1200/100000: loss: 1324.188
training... 1300/100000: loss: 1309.671
training... 1400/100000: loss: 1302.440
training... 1500/100000: loss: 1286.959
training... 1600/100000: loss: 1205.219
training... 1700/100000: loss: 1199.066
training... 1800/100000: loss: 1146.027
training... 1900/100000: loss: 1149.307
training... 2000/100000: loss: 1077.342
training... 2100/100000: loss: 1050.683
training... 2200/100000: loss: 1007.136
training... 2300/100000: loss: 1009.823
training... 2400/100000: loss: 985.903
training... 2500/100000: loss: 965.221
training... 2600/100000: loss: 927.336
training... 2700/100000: loss: 929.748
training... 2800/100000: loss: 913.988
training... 2900/100000: loss: 838.637
training... 3000/100000: loss: 822.404
training... 3100/100000: loss: 789.215
training... 3200/100000: loss: 807.704
training... 3300/100000: loss: 753.894
training... 3400/100000: loss: 751.284
training... 3500/100000: loss: 709.449
training... 3600/100000: loss: 713.252
training... 3700/100000: loss: 738.721
training... 3800/100000: loss: 713.795
training... 3900/100000: loss: 719.330
training... 4000/100000: loss: 718.118
training... 4100/100000: loss: 671.694
training... 4200/100000: loss: 700.512
training... 4300/100000: loss: 676.299
training... 4400/100000: loss: 672.345
training... 4500/100000: loss: 696.647
training... 4600/100000: loss: 656.541
training... 4700/100000: loss: 673.355
training... 4800/100000: loss: 640.963
training... 4900/100000: loss: 639.038
training... 5000/100000: loss: 669.212
training... 5100/100000: loss: 661.595
training... 5200/100000: loss: 635.202
training... 5300/100000: loss: 657.294
training... 5400/100000: loss: 621.731
training... 5500/100000: loss: 664.787
training... 5600/100000: loss: 603.986
training... 5700/100000: loss: 647.433
training... 5800/100000: loss: 603.118
training... 5900/100000: loss: 617.086
training... 6000/100000: loss: 603.456
training... 6100/100000: loss: 603.638
training... 6200/100000: loss: 618.328
training... 6300/100000: loss: 623.144
training... 6400/100000: loss: 620.985
training... 6500/100000: loss: 598.432
training... 6600/100000: loss: 547.082
training... 6700/100000: loss: 575.028
training... 6800/100000: loss: 560.231
training... 6900/100000: loss: 534.982
training... 7000/100000: loss: 544.162
training... 7100/100000: loss: 527.802
training... 7200/100000: loss: 536.127
training... 7300/100000: loss: 518.037
training... 7400/100000: loss: 527.980
training... 7500/100000: loss: 513.179
training... 7600/100000: loss: 507.856
training... 7700/100000: loss: 511.743
training... 7800/100000: loss: 500.089
training... 7900/100000: loss: 515.399
training... 8000/100000: loss: 463.907
training... 8100/100000: loss: 467.565
training... 8200/100000: loss: 506.161
training... 8300/100000: loss: 481.568
training... 8400/100000: loss: 505.486
training... 8500/100000: loss: 461.643
training... 8600/100000: loss: 486.291
training... 8700/100000: loss: 490.255
training... 8800/100000: loss: 474.718
training... 8900/100000: loss: 480.687
training... 9000/100000: loss: 471.688
training... 9100/100000: loss: 448.617
training... 9200/100000: loss: 478.945
training... 9300/100000: loss: 454.808
training... 9400/100000: loss: 452.150
training... 9500/100000: loss: 428.219
training... 9600/100000: loss: 457.375
training... 9700/100000: loss: 452.633
training... 9800/100000: loss: 458.994
training... 9900/100000: loss: 457.464
training... 10000/100000: loss: 437.892
training... 10100/100000: loss: 429.932
training... 10200/100000: loss: 420.080
training... 10300/100000: loss: 441.880
training... 10400/100000: loss: 455.085
training... 10500/100000: loss: 445.030
training... 10600/100000: loss: 449.502
training... 10700/100000: loss: 400.810
training... 10800/100000: loss: 438.568
training... 10900/100000: loss: 427.599
training... 11000/100000: loss: 483.981
training... 11100/100000: loss: 424.684
training... 11200/100000: loss: 426.913
training... 11300/100000: loss: 412.646
training... 11400/100000: loss: 488.072
training... 11500/100000: loss: 426.847
training... 11600/100000: loss: 425.121
training... 11700/100000: loss: 435.278
training... 11800/100000: loss: 420.685
training... 11900/100000: loss: 406.916
training... 12000/100000: loss: 413.584
training... 12100/100000: loss: 406.950
training... 12200/100000: loss: 414.436
training... 12300/100000: loss: 424.727
training... 12400/100000: loss: 431.510
training... 12500/100000: loss: 416.323
training... 12600/100000: loss: 429.033
training... 12700/100000: loss: 406.873
training... 12800/100000: loss: 396.477
training... 12900/100000: loss: 401.107
training... 13000/100000: loss: 417.464
training... 13100/100000: loss: 389.754
training... 13200/100000: loss: 407.306
training... 13300/100000: loss: 392.574
training... 13400/100000: loss: 398.528
training... 13500/100000: loss: 399.619
training... 13600/100000: loss: 379.284
training... 13700/100000: loss: 403.077
training... 13800/100000: loss: 364.601
training... 13900/100000: loss: 392.119
training... 14000/100000: loss: 405.390
training... 14100/100000: loss: 402.056
training... 14200/100000: loss: 371.039
training... 14300/100000: loss: 384.479
training... 14400/100000: loss: 401.360
training... 14500/100000: loss: 381.321
training... 14600/100000: loss: 398.527
training... 14700/100000: loss: 387.104
training... 14800/100000: loss: 440.601
training... 14900/100000: loss: 370.183
training... 15000/100000: loss: 375.086
training... 15100/100000: loss: 370.045
training... 15200/100000: loss: 375.172
training... 15300/100000: loss: 390.119
training... 15400/100000: loss: 391.933
training... 15500/100000: loss: 371.136
training... 15600/100000: loss: 389.192
training... 15700/100000: loss: 389.735
training... 15800/100000: loss: 355.840
training... 15900/100000: loss: 377.269
training... 16000/100000: loss: 378.145
training... 16100/100000: loss: 384.824
training... 16200/100000: loss: 362.005
training... 16300/100000: loss: 377.295
training... 16400/100000: loss: 382.551
training... 16500/100000: loss: 350.991
training... 16600/100000: loss: 397.975
training... 16700/100000: loss: 367.213
training... 16800/100000: loss: 365.375
training... 16900/100000: loss: 370.067
training... 17000/100000: loss: 377.284
training... 17100/100000: loss: 369.080
training... 17200/100000: loss: 410.612
training... 17300/100000: loss: 355.754
training... 17400/100000: loss: 341.683
training... 17500/100000: loss: 346.387
training... 17600/100000: loss: 334.575
training... 17700/100000: loss: 355.513
training... 17800/100000: loss: 347.613
training... 17900/100000: loss: 354.437
training... 18000/100000: loss: 354.197
training... 18100/100000: loss: 344.936
training... 18200/100000: loss: 363.257
training... 18300/100000: loss: 349.234
training... 18400/100000: loss: 344.246
training... 18500/100000: loss: 346.458
training... 18600/100000: loss: 367.784
training... 18700/100000: loss: 368.488
training... 18800/100000: loss: 347.746
training... 18900/100000: loss: 349.234
training... 19000/100000: loss: 370.755
training... 19100/100000: loss: 361.308
training... 19200/100000: loss: 374.994
training... 19300/100000: loss: 351.869
training... 19400/100000: loss: 363.524
training... 19500/100000: loss: 350.578
training... 19600/100000: loss: 356.569
training... 19700/100000: loss: 351.418
training... 19800/100000: loss: 328.586
training... 19900/100000: loss: 351.698
training... 20000/100000: loss: 343.958
training... 20100/100000: loss: 355.821
training... 20200/100000: loss: 343.182
training... 20300/100000: loss: 350.653
training... 20400/100000: loss: 374.920
training... 20500/100000: loss: 347.205
training... 20600/100000: loss: 338.822
training... 20700/100000: loss: 333.109
training... 20800/100000: loss: 350.894
training... 20900/100000: loss: 342.276
training... 21000/100000: loss: 341.106
training... 21100/100000: loss: 351.045
training... 21200/100000: loss: 325.930
training... 21300/100000: loss: 343.585
training... 21400/100000: loss: 359.750
training... 21500/100000: loss: 329.640
training... 21600/100000: loss: 328.258
training... 21700/100000: loss: 371.807
training... 21800/100000: loss: 316.261
training... 21900/100000: loss: 350.308
training... 22000/100000: loss: 346.546
training... 22100/100000: loss: 356.744
training... 22200/100000: loss: 325.015
training... 22300/100000: loss: 350.545
training... 22400/100000: loss: 347.362
training... 22500/100000: loss: 345.311
training... 22600/100000: loss: 332.303
training... 22700/100000: loss: 322.204
training... 22800/100000: loss: 339.567
training... 22900/100000: loss: 351.614
training... 23000/100000: loss: 338.235
training... 23100/100000: loss: 346.395
training... 23200/100000: loss: 319.389
training... 23300/100000: loss: 320.112
training... 23400/100000: loss: 352.768
training... 23500/100000: loss: 350.877
training... 23600/100000: loss: 326.581
training... 23700/100000: loss: 337.625
training... 23800/100000: loss: 331.300
training... 23900/100000: loss: 327.009
training... 24000/100000: loss: 332.619
training... 24100/100000: loss: 336.051
training... 24200/100000: loss: 337.757
training... 24300/100000: loss: 309.891
training... 24400/100000: loss: 327.767
training... 24500/100000: loss: 324.958
training... 24600/100000: loss: 333.416
training... 24700/100000: loss: 316.529
training... 24800/100000: loss: 304.968
training... 24900/100000: loss: 318.506
training... 25000/100000: loss: 335.076
training... 25100/100000: loss: 319.830
training... 25200/100000: loss: 320.287
training... 25300/100000: loss: 332.710
training... 25400/100000: loss: 336.654
training... 25500/100000: loss: 332.748
training... 25600/100000: loss: 302.103
training... 25700/100000: loss: 328.024
training... 25800/100000: loss: 341.429
training... 25900/100000: loss: 339.878
training... 26000/100000: loss: 314.737
training... 26100/100000: loss: 312.751
training... 26200/100000: loss: 337.041
training... 26300/100000: loss: 319.556
training... 26400/100000: loss: 331.109
training... 26500/100000: loss: 296.561
training... 26600/100000: loss: 341.827
training... 26700/100000: loss: 325.388
training... 26800/100000: loss: 316.785
training... 26900/100000: loss: 315.823
training... 27000/100000: loss: 320.728
training... 27100/100000: loss: 316.482
training... 27200/100000: loss: 334.557
training... 27300/100000: loss: 315.855
training... 27400/100000: loss: 343.592
training... 27500/100000: loss: 318.228
training... 27600/100000: loss: 310.858
training... 27700/100000: loss: 316.634
training... 27800/100000: loss: 313.289
training... 27900/100000: loss: 307.520
training... 28000/100000: loss: 316.229
training... 28100/100000: loss: 304.469
training... 28200/100000: loss: 308.387
training... 28300/100000: loss: 297.870
training... 28400/100000: loss: 304.782
training... 28500/100000: loss: 315.132
training... 28600/100000: loss: 311.135
training... 28700/100000: loss: 308.812
training... 28800/100000: loss: 309.638
training... 28900/100000: loss: 330.873
training... 29000/100000: loss: 318.346
training... 29100/100000: loss: 334.593
training... 29200/100000: loss: 289.162
training... 29300/100000: loss: 291.101
training... 29400/100000: loss: 311.733
training... 29500/100000: loss: 302.187
training... 29600/100000: loss: 330.803
training... 29700/100000: loss: 302.386
training... 29800/100000: loss: 296.551
training... 29900/100000: loss: 331.995
training... 30000/100000: loss: 320.385
training... 30100/100000: loss: 299.648
training... 30200/100000: loss: 306.038
training... 30300/100000: loss: 315.281
training... 30400/100000: loss: 292.766
training... 30500/100000: loss: 299.752
training... 30600/100000: loss: 288.998
training... 30700/100000: loss: 293.553
training... 30800/100000: loss: 300.286
training... 30900/100000: loss: 302.123
training... 31000/100000: loss: 312.506
training... 31100/100000: loss: 307.601
training... 31200/100000: loss: 275.532
training... 31300/100000: loss: 293.178
training... 31400/100000: loss: 294.466
training... 31500/100000: loss: 284.371
training... 31600/100000: loss: 294.187
training... 31700/100000: loss: 309.536
training... 31800/100000: loss: 304.611
training... 31900/100000: loss: 293.379
training... 32000/100000: loss: 297.798
training... 32100/100000: loss: 306.282
training... 32200/100000: loss: 294.283
training... 32300/100000: loss: 307.001
training... 32400/100000: loss: 316.399
training... 32500/100000: loss: 308.317
training... 32600/100000: loss: 292.194
training... 32700/100000: loss: 301.423
training... 32800/100000: loss: 317.251
training... 32900/100000: loss: 308.865
training... 33000/100000: loss: 274.932
training... 33100/100000: loss: 289.180
training... 33200/100000: loss: 295.036
training... 33300/100000: loss: 299.041
training... 33400/100000: loss: 282.902
training... 33500/100000: loss: 294.393
training... 33600/100000: loss: 265.341
training... 33700/100000: loss: 292.079
training... 33800/100000: loss: 302.528
training... 33900/100000: loss: 297.539
training... 34000/100000: loss: 285.963
training... 34100/100000: loss: 302.850
training... 34200/100000: loss: 290.962
training... 34300/100000: loss: 294.967
training... 34400/100000: loss: 302.593
training... 34500/100000: loss: 279.625
training... 34600/100000: loss: 298.008
training... 34700/100000: loss: 302.813
training... 34800/100000: loss: 292.115
training... 34900/100000: loss: 275.839
training... 35000/100000: loss: 291.713
training... 35100/100000: loss: 300.417
training... 35200/100000: loss: 281.434
training... 35300/100000: loss: 294.732
training... 35400/100000: loss: 298.402
training... 35500/100000: loss: 280.818
training... 35600/100000: loss: 279.906
training... 35700/100000: loss: 276.840
training... 35800/100000: loss: 290.018
training... 35900/100000: loss: 289.908
training... 36000/100000: loss: 302.038
training... 36100/100000: loss: 287.619
training... 36200/100000: loss: 279.853
training... 36300/100000: loss: 282.354
training... 36400/100000: loss: 276.252
training... 36500/100000: loss: 273.117
training... 36600/100000: loss: 300.750
training... 36700/100000: loss: 282.656
training... 36800/100000: loss: 281.366
training... 36900/100000: loss: 276.995
training... 37000/100000: loss: 285.801
training... 37100/100000: loss: 275.379
training... 37200/100000: loss: 280.448
training... 37300/100000: loss: 273.529
training... 37400/100000: loss: 276.190
training... 37500/100000: loss: 281.193
training... 37600/100000: loss: 275.607
training... 37700/100000: loss: 262.398
training... 37800/100000: loss: 280.737
training... 37900/100000: loss: 275.618
training... 38000/100000: loss: 277.506
training... 38100/100000: loss: 280.437
training... 38200/100000: loss: 306.368
training... 38300/100000: loss: 278.516
training... 38400/100000: loss: 266.799
training... 38500/100000: loss: 270.192
training... 38600/100000: loss: 284.559
training... 38700/100000: loss: 291.022
training... 38800/100000: loss: 280.212
training... 38900/100000: loss: 279.219
training... 39000/100000: loss: 289.033
training... 39100/100000: loss: 269.368
training... 39200/100000: loss: 280.907
training... 39300/100000: loss: 286.395
training... 39400/100000: loss: 296.007
training... 39500/100000: loss: 288.867
training... 39600/100000: loss: 276.385
training... 39700/100000: loss: 274.938
training... 39800/100000: loss: 287.762
training... 39900/100000: loss: 302.197
training... 40000/100000: loss: 295.251
training... 40100/100000: loss: 288.754
training... 40200/100000: loss: 290.978
training... 40300/100000: loss: 278.714
training... 40400/100000: loss: 269.850
training... 40500/100000: loss: 273.614
training... 40600/100000: loss: 276.655
training... 40700/100000: loss: 280.058
training... 40800/100000: loss: 283.599
training... 40900/100000: loss: 268.937
training... 41000/100000: loss: 282.341
training... 41100/100000: loss: 274.478
training... 41200/100000: loss: 254.175
training... 41300/100000: loss: 305.096
training... 41400/100000: loss: 293.478
training... 41500/100000: loss: 278.047
training... 41600/100000: loss: 263.327
training... 41700/100000: loss: 267.814
training... 41800/100000: loss: 279.621
training... 41900/100000: loss: 288.477
training... 42000/100000: loss: 275.689
training... 42100/100000: loss: 274.359
training... 42200/100000: loss: 278.520
training... 42300/100000: loss: 303.187
training... 42400/100000: loss: 275.064
training... 42500/100000: loss: 286.148
training... 42600/100000: loss: 288.663
training... 42700/100000: loss: 273.411
training... 42800/100000: loss: 281.645
training... 42900/100000: loss: 285.646
training... 43000/100000: loss: 284.337
training... 43100/100000: loss: 283.846
training... 43200/100000: loss: 277.043
training... 43300/100000: loss: 284.014
training... 43400/100000: loss: 270.430
training... 43500/100000: loss: 287.983
training... 43600/100000: loss: 272.284
training... 43700/100000: loss: 278.390
training... 43800/100000: loss: 282.496
training... 43900/100000: loss: 279.599
training... 44000/100000: loss: 250.584
training... 44100/100000: loss: 270.675
training... 44200/100000: loss: 270.032
training... 44300/100000: loss: 275.758
training... 44400/100000: loss: 284.657
training... 44500/100000: loss: 280.790
training... 44600/100000: loss: 280.447
training... 44700/100000: loss: 266.425
training... 44800/100000: loss: 279.865
training... 44900/100000: loss: 256.773
training... 45000/100000: loss: 276.229
training... 45100/100000: loss: 283.342
training... 45200/100000: loss: 272.872
training... 45300/100000: loss: 278.343
training... 45400/100000: loss: 269.281
training... 45500/100000: loss: 260.612
training... 45600/100000: loss: 268.504
training... 45700/100000: loss: 282.138
training... 45800/100000: loss: 272.862
training... 45900/100000: loss: 276.092
training... 46000/100000: loss: 269.175
training... 46100/100000: loss: 270.226
training... 46200/100000: loss: 273.646
training... 46300/100000: loss: 255.968
training... 46400/100000: loss: 279.205
training... 46500/100000: loss: 238.088
training... 46600/100000: loss: 276.421
training... 46700/100000: loss: 276.286
training... 46800/100000: loss: 255.686
training... 46900/100000: loss: 262.937
training... 47000/100000: loss: 250.359
training... 47100/100000: loss: 270.328
training... 47200/100000: loss: 272.806
training... 47300/100000: loss: 283.951
training... 47400/100000: loss: 278.567
training... 47500/100000: loss: 266.104
training... 47600/100000: loss: 277.952
training... 47700/100000: loss: 262.406
training... 47800/100000: loss: 270.826
training... 47900/100000: loss: 272.533
training... 48000/100000: loss: 279.695
training... 48100/100000: loss: 291.350
training... 48200/100000: loss: 265.799
training... 48300/100000: loss: 284.193
training... 48400/100000: loss: 281.781
training... 48500/100000: loss: 287.682
training... 48600/100000: loss: 269.021
training... 48700/100000: loss: 268.424
training... 48800/100000: loss: 274.519
training... 48900/100000: loss: 282.353
training... 49000/100000: loss: 269.862
training... 49100/100000: loss: 251.876
training... 49200/100000: loss: 286.496
training... 49300/100000: loss: 272.492
training... 49400/100000: loss: 303.855
training... 49500/100000: loss: 265.479
training... 49600/100000: loss: 274.832
training... 49700/100000: loss: 280.655
training... 49800/100000: loss: 273.032
training... 49900/100000: loss: 254.855
training... 50000/100000: loss: 247.080
training... 50100/100000: loss: 260.360
training... 50200/100000: loss: 258.360
training... 50300/100000: loss: 276.578
training... 50400/100000: loss: 258.758
training... 50500/100000: loss: 274.865
training... 50600/100000: loss: 291.261
training... 50700/100000: loss: 284.536
training... 50800/100000: loss: 268.223
training... 50900/100000: loss: 281.736
training... 51000/100000: loss: 272.692
training... 51100/100000: loss: 267.248
training... 51200/100000: loss: 264.059
training... 51300/100000: loss: 269.031
training... 51400/100000: loss: 265.303
training... 51500/100000: loss: 271.248
training... 51600/100000: loss: 272.603
training... 51700/100000: loss: 269.285
training... 51800/100000: loss: 257.868
training... 51900/100000: loss: 267.228
training... 52000/100000: loss: 268.781
training... 52100/100000: loss: 276.646
training... 52200/100000: loss: 272.928
training... 52300/100000: loss: 273.602
training... 52400/100000: loss: 279.319
training... 52500/100000: loss: 284.559
training... 52600/100000: loss: 255.211
training... 52700/100000: loss: 285.913
training... 52800/100000: loss: 271.357
training... 52900/100000: loss: 252.427
training... 53000/100000: loss: 263.338
training... 53100/100000: loss: 264.366
training... 53200/100000: loss: 277.950
training... 53300/100000: loss: 266.078
training... 53400/100000: loss: 280.141
training... 53500/100000: loss: 270.984
training... 53600/100000: loss: 260.022
training... 53700/100000: loss: 267.650
training... 53800/100000: loss: 266.812
training... 53900/100000: loss: 254.143
training... 54000/100000: loss: 261.207
training... 54100/100000: loss: 284.041
training... 54200/100000: loss: 261.369
training... 54300/100000: loss: 264.207
training... 54400/100000: loss: 267.313
training... 54500/100000: loss: 258.606
training... 54600/100000: loss: 260.955
training... 54700/100000: loss: 268.530
training... 54800/100000: loss: 269.056
training... 54900/100000: loss: 256.509
training... 55000/100000: loss: 268.704
training... 55100/100000: loss: 254.291
training... 55200/100000: loss: 278.040
training... 55300/100000: loss: 255.918
training... 55400/100000: loss: 276.701
training... 55500/100000: loss: 264.201
training... 55600/100000: loss: 278.058
training... 55700/100000: loss: 244.115
training... 55800/100000: loss: 260.098
training... 55900/100000: loss: 270.915
training... 56000/100000: loss: 259.960
training... 56100/100000: loss: 270.854
training... 56200/100000: loss: 261.587
training... 56300/100000: loss: 268.610
training... 56400/100000: loss: 260.328
training... 56500/100000: loss: 277.425
training... 56600/100000: loss: 252.503
training... 56700/100000: loss: 258.357
training... 56800/100000: loss: 248.805
training... 56900/100000: loss: 248.674
training... 57000/100000: loss: 269.076
training... 57100/100000: loss: 257.826
training... 57200/100000: loss: 259.700
training... 57300/100000: loss: 254.909
training... 57400/100000: loss: 260.209
training... 57500/100000: loss: 250.192
training... 57600/100000: loss: 274.550
training... 57700/100000: loss: 265.810
training... 57800/100000: loss: 251.693
training... 57900/100000: loss: 276.141
training... 58000/100000: loss: 247.752
training... 58100/100000: loss: 268.512
training... 58200/100000: loss: 268.052
training... 58300/100000: loss: 274.556
training... 58400/100000: loss: 242.444
training... 58500/100000: loss: 250.343
training... 58600/100000: loss: 247.669
training... 58700/100000: loss: 267.909
training... 58800/100000: loss: 270.197
training... 58900/100000: loss: 262.300
training... 59000/100000: loss: 272.317
training... 59100/100000: loss: 281.394
training... 59200/100000: loss: 264.066
training... 59300/100000: loss: 279.003
training... 59400/100000: loss: 252.851
training... 59500/100000: loss: 262.986
training... 59600/100000: loss: 248.597
training... 59700/100000: loss: 275.771
training... 59800/100000: loss: 270.403
training... 59900/100000: loss: 270.171
training... 60000/100000: loss: 271.093
training... 60100/100000: loss: 259.118
training... 60200/100000: loss: 281.064
training... 60300/100000: loss: 263.078
training... 60400/100000: loss: 264.053
training... 60500/100000: loss: 269.951
training... 60600/100000: loss: 269.335
training... 60700/100000: loss: 282.108
training... 60800/100000: loss: 269.532
training... 60900/100000: loss: 261.981
training... 61000/100000: loss: 274.621
training... 61100/100000: loss: 267.375
training... 61200/100000: loss: 270.685
training... 61300/100000: loss: 264.068
training... 61400/100000: loss: 273.982
training... 61500/100000: loss: 250.532
training... 61600/100000: loss: 264.071
training... 61700/100000: loss: 260.735
training... 61800/100000: loss: 265.295
training... 61900/100000: loss: 247.459
training... 62000/100000: loss: 261.400
training... 62100/100000: loss: 262.130
training... 62200/100000: loss: 263.433
training... 62300/100000: loss: 241.573
training... 62400/100000: loss: 254.533
training... 62500/100000: loss: 272.266
training... 62600/100000: loss: 246.943
training... 62700/100000: loss: 255.231
training... 62800/100000: loss: 251.100
training... 62900/100000: loss: 248.487
training... 63000/100000: loss: 271.183
training... 63100/100000: loss: 269.426
training... 63200/100000: loss: 242.157
training... 63300/100000: loss: 256.592
training... 63400/100000: loss: 269.657
training... 63500/100000: loss: 255.968
training... 63600/100000: loss: 262.176
training... 63700/100000: loss: 242.109
training... 63800/100000: loss: 261.891
training... 63900/100000: loss: 261.708
training... 64000/100000: loss: 269.398
training... 64100/100000: loss: 258.472
training... 64200/100000: loss: 252.841
training... 64300/100000: loss: 259.674
training... 64400/100000: loss: 248.614
training... 64500/100000: loss: 273.742
training... 64600/100000: loss: 256.111
training... 64700/100000: loss: 250.025
training... 64800/100000: loss: 263.346
training... 64900/100000: loss: 270.252
training... 65000/100000: loss: 243.816
training... 65100/100000: loss: 252.126
training... 65200/100000: loss: 269.683
training... 65300/100000: loss: 252.229
training... 65400/100000: loss: 244.553
training... 65500/100000: loss: 265.690
training... 65600/100000: loss: 245.858
training... 65700/100000: loss: 261.813
training... 65800/100000: loss: 254.677
training... 65900/100000: loss: 267.374
training... 66000/100000: loss: 263.273
training... 66100/100000: loss: 262.836
training... 66200/100000: loss: 271.287
training... 66300/100000: loss: 270.516
training... 66400/100000: loss: 266.738
training... 66500/100000: loss: 257.866
training... 66600/100000: loss: 262.693
training... 66700/100000: loss: 270.944
training... 66800/100000: loss: 277.474
training... 66900/100000: loss: 277.922
training... 67000/100000: loss: 255.267
training... 67100/100000: loss: 248.331
training... 67200/100000: loss: 267.286
training... 67300/100000: loss: 252.747
training... 67400/100000: loss: 251.484
training... 67500/100000: loss: 273.935
training... 67600/100000: loss: 265.926
training... 67700/100000: loss: 254.600
training... 67800/100000: loss: 258.211
training... 67900/100000: loss: 261.378
training... 68000/100000: loss: 247.402
training... 68100/100000: loss: 264.513
training... 68200/100000: loss: 267.304
training... 68300/100000: loss: 254.188
training... 68400/100000: loss: 262.942
training... 68500/100000: loss: 255.598
training... 68600/100000: loss: 258.770
training... 68700/100000: loss: 263.155
training... 68800/100000: loss: 272.977
training... 68900/100000: loss: 249.055
training... 69000/100000: loss: 260.278
training... 69100/100000: loss: 284.156
training... 69200/100000: loss: 267.253
training... 69300/100000: loss: 247.169
training... 69400/100000: loss: 256.621
training... 69500/100000: loss: 269.707
training... 69600/100000: loss: 259.669
training... 69700/100000: loss: 250.465
training... 69800/100000: loss: 275.740
training... 69900/100000: loss: 268.424
training... 70000/100000: loss: 257.132
training... 70100/100000: loss: 261.608
training... 70200/100000: loss: 271.301
training... 70300/100000: loss: 269.357
training... 70400/100000: loss: 259.335
training... 70500/100000: loss: 246.977
training... 70600/100000: loss: 258.274
training... 70700/100000: loss: 263.762
training... 70800/100000: loss: 255.063
training... 70900/100000: loss: 251.695
training... 71000/100000: loss: 262.018
training... 71100/100000: loss: 271.710
training... 71200/100000: loss: 256.386
training... 71300/100000: loss: 267.088
training... 71400/100000: loss: 241.190
training... 71500/100000: loss: 268.239
training... 71600/100000: loss: 259.293
training... 71700/100000: loss: 247.450
training... 71800/100000: loss: 253.751
training... 71900/100000: loss: 258.432
training... 72000/100000: loss: 270.739
training... 72100/100000: loss: 254.173
training... 72200/100000: loss: 259.240
training... 72300/100000: loss: 261.829
training... 72400/100000: loss: 266.697
training... 72500/100000: loss: 267.774
training... 72600/100000: loss: 265.921
training... 72700/100000: loss: 261.574
training... 72800/100000: loss: 271.588
training... 72900/100000: loss: 248.496
training... 73000/100000: loss: 250.097
training... 73100/100000: loss: 269.328
training... 73200/100000: loss: 244.104
training... 73300/100000: loss: 244.903
training... 73400/100000: loss: 259.598
training... 73500/100000: loss: 253.458
training... 73600/100000: loss: 246.908
training... 73700/100000: loss: 277.671
training... 73800/100000: loss: 247.636
training... 73900/100000: loss: 254.446
training... 74000/100000: loss: 258.859
training... 74100/100000: loss: 238.946
training... 74200/100000: loss: 258.520
training... 74300/100000: loss: 248.014
training... 74400/100000: loss: 269.321
training... 74500/100000: loss: 266.578
training... 74600/100000: loss: 255.487
training... 74700/100000: loss: 264.412
training... 74800/100000: loss: 256.672
training... 74900/100000: loss: 242.318
training... 75000/100000: loss: 255.028
training... 75100/100000: loss: 242.735
training... 75200/100000: loss: 255.786
training... 75300/100000: loss: 274.680
training... 75400/100000: loss: 256.392
training... 75500/100000: loss: 263.412
training... 75600/100000: loss: 257.728
training... 75700/100000: loss: 236.964
training... 75800/100000: loss: 275.148
training... 75900/100000: loss: 260.804
training... 76000/100000: loss: 265.939
training... 76100/100000: loss: 271.913
training... 76200/100000: loss: 250.962
training... 76300/100000: loss: 251.611
training... 76400/100000: loss: 256.395
training... 76500/100000: loss: 253.176
training... 76600/100000: loss: 256.751
training... 76700/100000: loss: 241.354
training... 76800/100000: loss: 261.678
training... 76900/100000: loss: 244.027
training... 77000/100000: loss: 260.550
training... 77100/100000: loss: 241.187
training... 77200/100000: loss: 266.798
training... 77300/100000: loss: 266.651
training... 77400/100000: loss: 263.358
training... 77500/100000: loss: 258.767
training... 77600/100000: loss: 251.142
training... 77700/100000: loss: 262.176
training... 77800/100000: loss: 242.632
training... 77900/100000: loss: 223.744
training... 78000/100000: loss: 260.839
training... 78100/100000: loss: 259.976
training... 78200/100000: loss: 242.759
training... 78300/100000: loss: 249.991
training... 78400/100000: loss: 272.023
training... 78500/100000: loss: 250.853
training... 78600/100000: loss: 252.356
training... 78700/100000: loss: 259.714
training... 78800/100000: loss: 247.513
training... 78900/100000: loss: 250.511
training... 79000/100000: loss: 270.559
training... 79100/100000: loss: 273.972
training... 79200/100000: loss: 255.165
training... 79300/100000: loss: 259.528
training... 79400/100000: loss: 248.189
training... 79500/100000: loss: 262.765
training... 79600/100000: loss: 256.934
training... 79700/100000: loss: 262.264
training... 79800/100000: loss: 235.794
training... 79900/100000: loss: 245.540
training... 80000/100000: loss: 251.393
training... 80100/100000: loss: 237.954
training... 80200/100000: loss: 262.793
training... 80300/100000: loss: 241.805
training... 80400/100000: loss: 272.032
training... 80500/100000: loss: 254.359
training... 80600/100000: loss: 245.499
training... 80700/100000: loss: 241.702
training... 80800/100000: loss: 246.499
training... 80900/100000: loss: 243.807
training... 81000/100000: loss: 257.073
training... 81100/100000: loss: 240.289
training... 81200/100000: loss: 265.771
training... 81300/100000: loss: 265.175
training... 81400/100000: loss: 260.835
training... 81500/100000: loss: 256.011
training... 81600/100000: loss: 255.731
training... 81700/100000: loss: 248.538
training... 81800/100000: loss: 258.558
training... 81900/100000: loss: 263.694
training... 82000/100000: loss: 255.626
training... 82100/100000: loss: 251.886
training... 82200/100000: loss: 240.305
training... 82300/100000: loss: 243.802
training... 82400/100000: loss: 264.476
training... 82500/100000: loss: 267.912
training... 82600/100000: loss: 267.312
training... 82700/100000: loss: 242.831
training... 82800/100000: loss: 257.689
training... 82900/100000: loss: 248.054
training... 83000/100000: loss: 246.412
training... 83100/100000: loss: 247.080
training... 83200/100000: loss: 238.257
training... 83300/100000: loss: 240.504
training... 83400/100000: loss: 249.074
training... 83500/100000: loss: 243.576
training... 83600/100000: loss: 249.218
training... 83700/100000: loss: 253.805
training... 83800/100000: loss: 253.007
training... 83900/100000: loss: 238.051
training... 84000/100000: loss: 262.369
training... 84100/100000: loss: 265.644
training... 84200/100000: loss: 250.407
training... 84300/100000: loss: 261.589
training... 84400/100000: loss: 251.102
training... 84500/100000: loss: 252.035
training... 84600/100000: loss: 246.562
training... 84700/100000: loss: 259.039
training... 84800/100000: loss: 259.568
training... 84900/100000: loss: 266.742
training... 85000/100000: loss: 249.980
training... 85100/100000: loss: 255.235
training... 85200/100000: loss: 256.955
training... 85300/100000: loss: 261.459
training... 85400/100000: loss: 245.480
training... 85500/100000: loss: 255.695
training... 85600/100000: loss: 255.486
training... 85700/100000: loss: 248.696
training... 85800/100000: loss: 239.418
training... 85900/100000: loss: 247.990
training... 86000/100000: loss: 249.661
training... 86100/100000: loss: 264.196
training... 86200/100000: loss: 258.533
training... 86300/100000: loss: 260.231
training... 86400/100000: loss: 243.255
training... 86500/100000: loss: 255.673
training... 86600/100000: loss: 253.008
training... 86700/100000: loss: 261.486
training... 86800/100000: loss: 257.801
training... 86900/100000: loss: 255.414
training... 87000/100000: loss: 241.898
training... 87100/100000: loss: 238.191
training... 87200/100000: loss: 255.715
training... 87300/100000: loss: 248.894
training... 87400/100000: loss: 262.795
training... 87500/100000: loss: 269.734
training... 87600/100000: loss: 264.500
training... 87700/100000: loss: 252.956
training... 87800/100000: loss: 264.114
training... 87900/100000: loss: 239.197
training... 88000/100000: loss: 228.672
training... 88100/100000: loss: 237.305
training... 88200/100000: loss: 262.592
training... 88300/100000: loss: 246.481
training... 88400/100000: loss: 238.641
training... 88500/100000: loss: 252.719
training... 88600/100000: loss: 242.909
training... 88700/100000: loss: 240.166
training... 88800/100000: loss: 278.326
training... 88900/100000: loss: 250.198
training... 89000/100000: loss: 247.299
training... 89100/100000: loss: 253.540
training... 89200/100000: loss: 269.677
training... 89300/100000: loss: 231.808
training... 89400/100000: loss: 256.062
training... 89500/100000: loss: 238.816
training... 89600/100000: loss: 256.550
training... 89700/100000: loss: 250.631
training... 89800/100000: loss: 240.447
training... 89900/100000: loss: 254.668
training... 90000/100000: loss: 242.111
training... 90100/100000: loss: 228.540
training... 90200/100000: loss: 255.909
training... 90300/100000: loss: 266.740
training... 90400/100000: loss: 269.228
training... 90500/100000: loss: 248.221
training... 90600/100000: loss: 239.458
training... 90700/100000: loss: 246.083
training... 90800/100000: loss: 255.327
training... 90900/100000: loss: 267.248
training... 91000/100000: loss: 268.364
training... 91100/100000: loss: 254.845
training... 91200/100000: loss: 251.683
training... 91300/100000: loss: 245.330
training... 91400/100000: loss: 274.478
training... 91500/100000: loss: 253.893
training... 91600/100000: loss: 246.134
training... 91700/100000: loss: 253.699
training... 91800/100000: loss: 272.364
training... 91900/100000: loss: 254.909
training... 92000/100000: loss: 248.089
training... 92100/100000: loss: 251.092
training... 92200/100000: loss: 236.065
training... 92300/100000: loss: 236.354
training... 92400/100000: loss: 253.179
training... 92500/100000: loss: 262.826
training... 92600/100000: loss: 241.198
training... 92700/100000: loss: 249.205
training... 92800/100000: loss: 239.415
training... 92900/100000: loss: 261.134
training... 93000/100000: loss: 255.482
training... 93100/100000: loss: 232.279
training... 93200/100000: loss: 241.242
training... 93300/100000: loss: 249.768
training... 93400/100000: loss: 252.668
training... 93500/100000: loss: 261.300
training... 93600/100000: loss: 247.410
training... 93700/100000: loss: 240.341
training... 93800/100000: loss: 249.603
training... 93900/100000: loss: 242.944
training... 94000/100000: loss: 239.488
training... 94100/100000: loss: 243.565
training... 94200/100000: loss: 241.538
training... 94300/100000: loss: 244.444
training... 94400/100000: loss: 248.684
training... 94500/100000: loss: 245.259
training... 94600/100000: loss: 246.169
training... 94700/100000: loss: 232.529
training... 94800/100000: loss: 244.671
training... 94900/100000: loss: 253.798
training... 95000/100000: loss: 257.289
training... 95100/100000: loss: 235.812
training... 95200/100000: loss: 242.801
training... 95300/100000: loss: 238.034
training... 95400/100000: loss: 247.420
training... 95500/100000: loss: 262.123
training... 95600/100000: loss: 249.606
training... 95700/100000: loss: 254.645
training... 95800/100000: loss: 244.376
training... 95900/100000: loss: 244.573
training... 96000/100000: loss: 263.327
training... 96100/100000: loss: 243.121
training... 96200/100000: loss: 244.992
training... 96300/100000: loss: 243.513
training... 96400/100000: loss: 255.246
training... 96500/100000: loss: 250.288
training... 96600/100000: loss: 241.578
training... 96700/100000: loss: 247.450
training... 96800/100000: loss: 253.919
training... 96900/100000: loss: 261.130
training... 97000/100000: loss: 244.012
training... 97100/100000: loss: 254.890
training... 97200/100000: loss: 240.890
training... 97300/100000: loss: 256.504
training... 97400/100000: loss: 266.025
training... 97500/100000: loss: 261.536
training... 97600/100000: loss: 254.629
training... 97700/100000: loss: 264.206
training... 97800/100000: loss: 247.653
training... 97900/100000: loss: 257.601
training... 98000/100000: loss: 248.087
training... 98100/100000: loss: 224.824
training... 98200/100000: loss: 228.053
training... 98300/100000: loss: 248.052
training... 98400/100000: loss: 254.063
training... 98500/100000: loss: 256.647
training... 98600/100000: loss: 246.558
training... 98700/100000: loss: 259.127
training... 98800/100000: loss: 246.066
training... 98900/100000: loss: 247.439
training... 99000/100000: loss: 253.953
training... 99100/100000: loss: 236.916
training... 99200/100000: loss: 258.037
training... 99300/100000: loss: 234.913
training... 99400/100000: loss: 237.755
training... 99500/100000: loss: 261.260
training... 99600/100000: loss: 273.863
training... 99700/100000: loss: 246.264
training... 99800/100000: loss: 263.143
training... 99900/100000: loss: 240.730
training... 100000/100000: loss: 242.060
>>> It elapsed 1452.46 seconds for training
>>> Star initialized.
>>> Draping...
>>> It takes 8.070 ms for draping
>>> OBJ file [./example/pose_0_10.obj] save completed.
>>> Draping...
>>> It takes 5.971 ms for draping
>>> OBJ file [./example/pose_1_10.obj] save completed.
>>> Draping...
>>> It takes 5.952 ms for draping
>>> OBJ file [./example/pose_2_10.obj] save completed.
>>> Draping...
>>> It takes 5.948 ms for draping
>>> OBJ file [./example/pose_3_10.obj] save completed.
>>> Draping...
>>> It takes 5.981 ms for draping
>>> OBJ file [./example/pose_4_10.obj] save completed.
>>> Draping...
>>> It takes 6.111 ms for draping
>>> OBJ file [./example/pose_5_10.obj] save completed.
>>> Draping...
>>> It takes 6.014 ms for draping
>>> OBJ file [./example/pose_6_10.obj] save completed.
>>> Draping...
>>> It takes 5.972 ms for draping
>>> OBJ file [./example/pose_7_10.obj] save completed.
>>> Draping...
>>> It takes 5.956 ms for draping
>>> OBJ file [./example/pose_8_10.obj] save completed.
>>> Draping...
>>> It takes 6.060 ms for draping
>>> OBJ file [./example/pose_9_10.obj] save completed.
>>> Draping...
>>> It takes 5.952 ms for draping
>>> OBJ file [./example/pose_10_10.obj] save completed.
